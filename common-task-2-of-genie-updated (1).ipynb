{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11151123,"sourceType":"datasetVersion","datasetId":6957107}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch_geometric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T01:19:30.339833Z","iopub.execute_input":"2025-04-08T01:19:30.340198Z","iopub.status.idle":"2025-04-08T01:19:35.986964Z","shell.execute_reply.started":"2025-04-08T01:19:30.340159Z","shell.execute_reply":"2025-04-08T01:19:35.986168Z"}},"outputs":[{"name":"stdout","text":"Collecting torch_geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.12)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.12.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.18.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2025.1.31)\nRequirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch_geometric) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torch_geometric) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torch_geometric) (2024.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch_geometric\nSuccessfully installed torch_geometric-2.6.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nprint(torch.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T01:19:35.988101Z","iopub.execute_input":"2025-04-08T01:19:35.988363Z","iopub.status.idle":"2025-04-08T01:19:39.121114Z","shell.execute_reply.started":"2025-04-08T01:19:35.988340Z","shell.execute_reply":"2025-04-08T01:19:39.120170Z"}},"outputs":[{"name":"stdout","text":"2.5.1+cu121\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport re\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch_geometric.data import Data\nfrom torch_geometric.nn import (\n    global_mean_pool, global_max_pool, global_add_pool,\n    GATConv, EdgeConv, SAGPooling,GATConv, EdgeConv, SAGEConv, SAGPooling, global_mean_pool, global_max_pool, global_add_pool, BatchNorm)\nfrom torch_geometric.nn.conv import MessagePassing\nfrom torch_geometric.transforms import BaseTransform\n\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T01:19:39.122856Z","iopub.execute_input":"2025-04-08T01:19:39.123204Z","iopub.status.idle":"2025-04-08T01:19:43.757540Z","shell.execute_reply.started":"2025-04-08T01:19:39.123183Z","shell.execute_reply":"2025-04-08T01:19:43.756598Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def extract_chunk_numbers(f):\n    m = re.search(r'chunk_(\\d+)_(\\d+)', f)\n    if m:\n        return (int(m.group(1)), int(m.group(2)))\n    else:\n        return (float('inf'), float('inf'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T01:19:43.758958Z","iopub.execute_input":"2025-04-08T01:19:43.759483Z","iopub.status.idle":"2025-04-08T01:19:43.763750Z","shell.execute_reply.started":"2025-04-08T01:19:43.759427Z","shell.execute_reply":"2025-04-08T01:19:43.762974Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class RandomPhiShift(BaseTransform):\n    def __init__(self, dphi=0.2):\n        self.dphi = dphi\n    \n    def __call__(self, data):\n        if data.pos.size(0) > 0:\n            shift = (torch.rand(1) * 2 - 1) * self.dphi\n            data.pos[:, 1] = data.pos[:, 1] + shift\n            data.pos[:, 1] = torch.atan2(torch.sin(data.pos[:, 1]), torch.cos(data.pos[:, 1]))\n        return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T01:19:43.764931Z","iopub.execute_input":"2025-04-08T01:19:43.765240Z","iopub.status.idle":"2025-04-08T01:19:43.800389Z","shell.execute_reply.started":"2025-04-08T01:19:43.765210Z","shell.execute_reply":"2025-04-08T01:19:43.799709Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class DynamicHybridGraph(nn.Module):\n    def __init__(self, k=5, alpha=0.5, beta=0.5):\n        super().__init__()\n        self.k = k\n        self.alpha = alpha\n        self.beta = beta\n        \n    def forward(self, x, pos, batch):\n        device = x.device\n        batch_size = batch.max().item() + 1\n        edge_index_list = []\n        edge_attr_list = []\n        \n        for i in range(batch_size):\n            mask = (batch == i)\n            x_batch = x[mask]\n            pos_batch = pos[mask]\n            if x_batch.size(0) <= 1:\n                continue\n            \n            # Compute distances\n            dist_geom = torch.cdist(pos_batch, pos_batch)\n            dist_feat = torch.cdist(x_batch, x_batch)\n            dist_combined = self.alpha * dist_geom + self.beta * dist_feat\n            \n            k_eff = min(self.k + 1, x_batch.size(0))\n            _, topk_indices = torch.topk(dist_combined, k=k_eff, largest=False, dim=1)\n            topk_indices = topk_indices[:, 1:]  # remove self-loop\n            \n            rows = torch.arange(x_batch.size(0), device=device).view(-1, 1).repeat(1, k_eff-1)\n            offset = mask.nonzero(as_tuple=True)[0].min().item()\n            edge_index = torch.stack([rows.reshape(-1), topk_indices.reshape(-1)], dim=0) + offset\n            \n            source_nodes = edge_index[0] - offset\n            target_nodes = edge_index[1] - offset\n            delta_eta = pos_batch[target_nodes, 0] - pos_batch[source_nodes, 0]\n            delta_phi = pos_batch[target_nodes, 1] - pos_batch[source_nodes, 1]\n            delta_phi = torch.atan2(torch.sin(delta_phi), torch.cos(delta_phi))\n            delta_r = torch.sqrt(delta_eta**2 + delta_phi**2)\n            delta_embed = x_batch[target_nodes] - x_batch[source_nodes]\n            delta_embed_norm = torch.norm(delta_embed, p=2, dim=1, keepdim=True)\n            edge_attr = torch.cat([\n                delta_eta.unsqueeze(1),\n                delta_phi.unsqueeze(1),\n                delta_r.unsqueeze(1),\n                delta_embed_norm\n            ], dim=1)\n            \n            edge_index_list.append(edge_index)\n            edge_attr_list.append(edge_attr)\n        \n        if not edge_index_list:\n            return (torch.zeros((2, 0), device=device, dtype=torch.long),\n                    torch.zeros((0, 4), device=device))\n        edge_index = torch.cat(edge_index_list, dim=1)\n        edge_attr = torch.cat(edge_attr_list, dim=0)\n        return edge_index, edge_attr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T01:19:43.801032Z","iopub.execute_input":"2025-04-08T01:19:43.801262Z","iopub.status.idle":"2025-04-08T01:19:43.818333Z","shell.execute_reply.started":"2025-04-08T01:19:43.801198Z","shell.execute_reply":"2025-04-08T01:19:43.817504Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def create_multiscale_knn(pos, k1=3, k2=5):\n    def knn_graph(pos, k):\n        n = pos.size(0)\n        if n <= 1:\n            return torch.zeros((2, 0), dtype=torch.long), torch.zeros((0, 3), dtype=torch.float)\n        dist = torch.cdist(pos, pos)\n        _, nn_idx = torch.topk(dist, k=min(k+1, n), dim=1, largest=False)\n        nn_idx = nn_idx[:, 1:]\n        rows = torch.arange(n).view(-1, 1).repeat(1, min(k, n-1))\n        edge_index = torch.stack([rows.reshape(-1), nn_idx.reshape(-1)], dim=0)\n        source_nodes = edge_index[0]\n        target_nodes = edge_index[1]\n        delta_eta = pos[target_nodes, 0] - pos[source_nodes, 0]\n        delta_phi = pos[target_nodes, 1] - pos[source_nodes, 1]\n        delta_phi = torch.atan2(torch.sin(delta_phi), torch.cos(delta_phi))\n        delta_r = torch.sqrt(delta_eta**2 + delta_phi**2)\n        edge_attr = torch.stack([delta_eta, delta_phi, delta_r], dim=1)\n        return edge_index, edge_attr\n    eidx_s, eattr_s = knn_graph(pos, k1)\n    eidx_l, eattr_l = knn_graph(pos, k2)\n    return eidx_s, eattr_s, eidx_l, eattr_l","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T01:19:43.818992Z","iopub.execute_input":"2025-04-08T01:19:43.819242Z","iopub.status.idle":"2025-04-08T01:19:43.838919Z","shell.execute_reply.started":"2025-04-08T01:19:43.819213Z","shell.execute_reply":"2025-04-08T01:19:43.838294Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class JetGraphProcessor:\n    def __init__(self, input_dir, transform=None, k=5, min_energy_threshold=1e-5):\n        self.input_dir = input_dir\n        self.transform = transform\n        self.k = k\n        self.min_energy_threshold = min_energy_threshold\n    \n    def _convert_to_graph(self, jet_image, label, m0, pt):\n        \"\"\"\n        Convert a jet image (3D numpy array) into a PyG Data object.\n        Assumes jet_image shape is (H, W, C).\n        \"\"\"\n        # Sum across channels to form a 2D projection\n        jet_image_2d = np.sum(jet_image, axis=2)\n        padded = np.pad(jet_image_2d, pad_width=1, mode='constant', constant_values=0)\n        non_zero_indices = np.where(jet_image_2d > self.min_energy_threshold)\n        points = []\n        features = []\n        for i, j in zip(non_zero_indices[0], non_zero_indices[1]):\n            pixel_eta = (i / 125.0 * 2 - 1) * 0.8\n            pixel_phi = (j / 125.0 * 2 - 1) * 0.8\n            energy_ecal = jet_image[i, j, 0]\n            energy_hcal = jet_image[i, j, 1]\n            energy_tracks = jet_image[i, j, 2]\n            total_energy = energy_ecal + energy_hcal + energy_tracks\n            pt_fraction = total_energy / (pt + 1e-9)\n            charged_fraction = energy_tracks / total_energy if total_energy > 0 else 0.0\n            local_sum = np.sum(padded[i:i+3, j:j+3])\n            angle_center = np.arctan2(j - 62.5, i - 62.5)\n            norm_dist_center = np.sqrt((i - 62.5)**2 + (j - 62.5)**2) / 62.5\n            features.append([\n                total_energy, energy_ecal, energy_hcal, energy_tracks,\n                pt_fraction, charged_fraction, local_sum,\n                pixel_eta, pixel_phi, np.log1p(total_energy),\n                np.sqrt(total_energy), angle_center, norm_dist_center\n            ])\n            points.append([pixel_eta, pixel_phi])\n        if len(points) == 0:\n            points = [[0, 0]]\n            features = [[0.0]*13]\n        x = torch.tensor(features, dtype=torch.float)\n        pos = torch.tensor(points, dtype=torch.float)\n        eidx_s, eattr_s, eidx_l, eattr_l = create_multiscale_knn(pos, k1=4, k2=8)\n        data = Data(\n            x=x,\n            pos=pos,\n            edge_index=eidx_s,\n            edge_attr=eattr_s,\n            y=torch.tensor([label], dtype=torch.long)\n        )\n        data.edge_index_large = eidx_l\n        data.edge_attr_large = eattr_l\n        data.global_features = torch.tensor([m0, pt], dtype=torch.float).unsqueeze(0)\n        return data\n    \n    def process_all_chunks(self):\n        \"\"\"\n        Process all .npz files from input_dir and accumulate graphs in memory.\n        \"\"\"\n        all_chunk_files = sorted(\n            [f for f in os.listdir(self.input_dir) if f.endswith('.npz')],\n            key=extract_chunk_numbers\n        )\n        all_graphs = []\n        for chunk_file in all_chunk_files:\n            print(f\"Processing {chunk_file} ...\")\n            data_npz = np.load(os.path.join(self.input_dir, chunk_file))\n            X_jets = data_npz['X_jets']\n            if 'y' in data_npz:\n                y = data_npz['y']\n            else:\n                raise KeyError(\"Label key 'y' not found in the dataset.\")\n            m0 = data_npz['m0']\n            pt = data_npz['pt']\n            for i in tqdm(range(X_jets.shape[0]), desc=f\"Processing {chunk_file}\"):\n                graph = self._convert_to_graph(X_jets[i], int(y[i]), m0[i], pt[i])\n                if self.transform:\n                    graph = self.transform(graph)\n                all_graphs.append(graph)\n        print(f\"Total graphs processed: {len(all_graphs)}\")\n        return all_graphs\n\n    def process_chunk(self):\n        \"\"\"\n        Process a single NPZ file (input_file) and return a list of graphs.\n        \"\"\"\n        data_npz = np.load(self.input_dir)  # here, input_dir is actually the file path\n        X_jets = data_npz['X_jets']\n        y = data_npz['y']\n        m0 = data_npz['m0']\n        pt = data_npz['pt']\n        all_graphs = []\n        for i in tqdm(range(X_jets.shape[0]), desc=\"Processing single chunk\"):\n            graph = self._convert_to_graph(X_jets[i], int(y[i]), m0[i], pt[i])\n            if self.transform:\n                graph = self.transform(graph)\n            all_graphs.append(graph)\n        return all_graphs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T01:19:43.839732Z","iopub.execute_input":"2025-04-08T01:19:43.839975Z","iopub.status.idle":"2025-04-08T01:19:43.863175Z","shell.execute_reply.started":"2025-04-08T01:19:43.839955Z","shell.execute_reply":"2025-04-08T01:19:43.862342Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class BatchNorm(nn.Module):\n    def __init__(self, num_features):\n        super().__init__()\n        self.bn = nn.BatchNorm1d(num_features)\n    \n    def forward(self, x):\n        return self.bn(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T01:19:43.865402Z","iopub.execute_input":"2025-04-08T01:19:43.865614Z","iopub.status.idle":"2025-04-08T01:19:43.881406Z","shell.execute_reply.started":"2025-04-08T01:19:43.865595Z","shell.execute_reply":"2025-04-08T01:19:43.880749Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class InMemoryJetGraphDataset(Dataset):\n    def __init__(self, graphs, transform=None):\n        self.graphs = graphs\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.graphs)\n    \n    def __getitem__(self, idx):\n        graph = self.graphs[idx]\n        if self.transform:\n            graph = self.transform(graph)\n        return graph","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T01:19:43.882340Z","iopub.execute_input":"2025-04-08T01:19:43.882567Z","iopub.status.idle":"2025-04-08T01:19:43.895620Z","shell.execute_reply.started":"2025-04-08T01:19:43.882547Z","shell.execute_reply":"2025-04-08T01:19:43.894942Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class CoordinateEmbedding(nn.Module):\n    def __init__(self, in_dim=2, out_dim=4):\n        super().__init__()\n        self.mlp = nn.Sequential(\n            nn.Linear(in_dim, out_dim),\n            nn.ReLU(),\n            nn.Linear(out_dim, out_dim)\n        )\n    \n    def forward(self, coords):\n        return self.mlp(coords)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T01:19:43.896326Z","iopub.execute_input":"2025-04-08T01:19:43.896580Z","iopub.status.idle":"2025-04-08T01:19:43.910382Z","shell.execute_reply.started":"2025-04-08T01:19:43.896550Z","shell.execute_reply":"2025-04-08T01:19:43.909685Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GATConv, EdgeConv, SAGEConv, SAGPooling, global_mean_pool, global_max_pool, global_add_pool, BatchNorm\n\nclass EnhancedJetGNN(nn.Module):\n    def __init__(self, node_dim, global_dim, hidden_dim=64, out_channels=2, \n                 num_layers=3, dropout=0.3, use_dynamic_graph=True, heads=4, \n                 use_sagpool=True, sagpool_ratio=0.5, use_sageconv=True):\n        super().__init__()\n        self.node_dim = node_dim\n        self.global_dim = global_dim\n        self.hidden_dim = hidden_dim\n        self.num_layers = num_layers\n        self.dropout = dropout\n        self.use_dynamic_graph = use_dynamic_graph\n        self.heads = heads\n        self.use_sagpool = use_sagpool\n        self.sagpool_ratio = sagpool_ratio\n        self.use_sageconv = use_sageconv\n\n        # Growth rate for dense connectivity.\n        self.growth_rate = hidden_dim // 2\n\n        # Coordinate embedding for (η, φ) at indices 7 and 8.\n        self.coord_embed = CoordinateEmbedding(in_dim=2, out_dim=4)\n        # Process the remaining node features.\n        self.feature_mlp = nn.Sequential(\n            nn.Linear(node_dim - 2, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, hidden_dim)\n        )\n        # Dedicated physics branch to extract physics-inspired features.\n        self.physics_mlp = nn.Sequential(\n            nn.Linear(node_dim, hidden_dim // 2),\n            nn.ReLU(),\n            nn.Linear(hidden_dim // 2, hidden_dim),\n            nn.ReLU()\n        )\n        # Combine coordinate embedding with processed features.\n        self.comb_mlp = nn.Sequential(\n            nn.Linear(hidden_dim + 4, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU()\n        )\n        # Global feature encoder.\n        self.global_encoder = nn.Sequential(\n            nn.Linear(global_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU()\n        )\n        # Dynamic adjacency module.\n        if use_dynamic_graph:\n            self.dynamic_graph = DynamicHybridGraph(k=5, alpha=0.5, beta=0.5)\n\n        # Build GNN layers with dense (concatenative) connections.\n        self.gnn_layers = nn.ModuleList()\n        self.batch_norms = nn.ModuleList()\n        self.transition_layers = nn.ModuleList()\n\n        # For the first layer, the input dimension is hidden_dim.\n        in_dim = hidden_dim\n\n        for i in range(num_layers):\n            if i % 2 == 0:\n                per_head_dim = self.growth_rate // heads\n                self.gnn_layers.append(\n                    GATConv(in_dim, per_head_dim, heads=heads, edge_dim=4, dropout=dropout)\n                )\n            else:\n                mlp = nn.Sequential(\n                    nn.Linear(in_dim * 2, hidden_dim),\n                    nn.ReLU(),\n                    nn.Dropout(dropout),\n                    nn.Linear(hidden_dim, self.growth_rate)\n                )\n                self.gnn_layers.append(\n                    EdgeConv(nn=mlp, aggr='mean')\n                )\n            self.batch_norms.append(BatchNorm(self.growth_rate))\n            self.transition_layers.append(\n                nn.Sequential(\n                    nn.Linear(in_dim + self.growth_rate, hidden_dim),\n                    nn.ReLU()\n                )\n            )\n            in_dim = hidden_dim\n        \n        # SAGEConv branch for parallel feature extraction.\n        if self.use_sageconv:\n            self.sage_layers = nn.ModuleList()\n            sage_in_dim = hidden_dim  # starting from same input dimension as after comb_mlp.\n            for i in range(num_layers):\n                self.sage_layers.append(SAGEConv(sage_in_dim, self.growth_rate, aggr='mean'))\n                sage_in_dim = hidden_dim  # We'll assume a transition layer similar to GNN branch not needed here.\n        \n        # Optional SAGPooling for hierarchical pooling.\n        if self.use_sagpool:\n            self.sagpool = SAGPooling(hidden_dim, ratio=self.sagpool_ratio)\n        \n        # Final classifier: multi-scale pooling (mean, max, sum) combined with global features.\n        self.classifier = nn.Sequential(\n            nn.Linear(hidden_dim * 3 + hidden_dim, hidden_dim * 2),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim * 2, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, out_channels)\n        )\n    \n    def forward(self, data):\n        x, batch = data.x, data.batch\n        edge_index, edge_attr = data.edge_index, data.edge_attr\n        pos = data.pos\n        if hasattr(data, 'global_features'):\n            global_features = data.global_features\n        else:\n            global_features = torch.zeros((batch.max().item()+1, self.global_dim), device=x.device)\n        if batch is None:\n            batch = torch.zeros(x.size(0), dtype=torch.long, device=x.device)\n        \n        # Save original node features for physics branch.\n        x_original = x.clone()\n        # Process coordinate features (assumed at indices 7 and 8).\n        coords = x[:, [7, 8]]\n        other_feats = torch.cat([x[:, :7], x[:, 9:]], dim=1)\n        coord_emb = self.coord_embed(coords)\n        feat_emb = self.feature_mlp(other_feats)\n        x = torch.cat([feat_emb, coord_emb], dim=1)\n        # Obtain additional physics-inspired features.\n        physics_emb = self.physics_mlp(x_original)\n        x = x + physics_emb\n        x = self.comb_mlp(x)\n        global_x = self.global_encoder(global_features)\n        \n        # Process through GNN branch with dense connectivity.\n        x_gnn = x\n        for i, conv in enumerate(self.gnn_layers):\n            if self.use_dynamic_graph:\n                edge_index, edge_attr = self.dynamic_graph(x_gnn, pos, batch)\n            if isinstance(conv, GATConv):\n                new_features = conv(x_gnn, edge_index, edge_attr=edge_attr)\n            else:\n                new_features = conv(x_gnn, edge_index)\n            new_features = self.batch_norms[i](new_features)\n            new_features = F.relu(new_features)\n            new_features = F.dropout(new_features, p=self.dropout, training=self.training)\n            concatenated = torch.cat([x_gnn, new_features], dim=1)\n            x_gnn = self.transition_layers[i](concatenated)\n        \n        # Process through SAGEConv branch if enabled.\n        if self.use_sageconv:\n            x_sage = x\n            for sage_conv in self.sage_layers:\n                x_sage = sage_conv(x_sage, edge_index)\n                x_sage = F.relu(x_sage)\n                x_sage = F.dropout(x_sage, p=self.dropout, training=self.training)\n            # Fuse the outputs by averaging.\n            x_fused = (x_gnn + x_sage) / 2.0\n        else:\n            x_fused = x_gnn\n        \n        # Optionally apply non-local block if implemented externally (not included here).\n        # if self.use_non_local:\n        #     x_fused = self.non_local(x_fused)\n        \n        # Apply SAGPooling if enabled.\n        if self.use_sagpool:\n            x_fused, edge_index, edge_attr, batch, _, _ = self.sagpool(x_fused, edge_index, edge_attr, batch=batch)\n        \n        pooled_mean = global_mean_pool(x_fused, batch)\n        pooled_max = global_max_pool(x_fused, batch)\n        pooled_sum = global_add_pool(x_fused, batch)\n        combined = torch.cat([pooled_mean, pooled_max, pooled_sum, global_x], dim=1)\n        out = self.classifier(combined)\n        return F.log_softmax(out, dim=-1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T01:19:43.910989Z","iopub.execute_input":"2025-04-08T01:19:43.911261Z","iopub.status.idle":"2025-04-08T01:19:43.929296Z","shell.execute_reply.started":"2025-04-08T01:19:43.911229Z","shell.execute_reply":"2025-04-08T01:19:43.928630Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def visualize_graph(graph, ax=None):\n    if ax is None:\n        fig, ax = plt.subplots()\n    pos = graph.pos.numpy()\n    ax.scatter(pos[:, 0], pos[:, 1], c='blue', s=30, label='Nodes')\n    # Plot edges\n    if graph.edge_index.size(1) > 0:\n        edge_index = graph.edge_index.numpy()\n        for i in range(edge_index.shape[1]):\n            src = pos[edge_index[0, i]]\n            dst = pos[edge_index[1, i]]\n            ax.plot([src[0], dst[0]], [src[1], dst[1]], c='gray', linewidth=0.5)\n    ax.set_title(f\"Graph (Label: {graph.y.item()})\")\n    ax.legend()\n    return ax","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T01:19:43.929982Z","iopub.execute_input":"2025-04-08T01:19:43.930247Z","iopub.status.idle":"2025-04-08T01:19:43.949198Z","shell.execute_reply.started":"2025-04-08T01:19:43.930227Z","shell.execute_reply":"2025-04-08T01:19:43.948594Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torch_geometric.data import Data, InMemoryDataset\nfrom torch_geometric.loader import DataLoader\nimport numpy as np\nfrom sklearn.metrics import (accuracy_score, precision_score, recall_score,\n                             f1_score, confusion_matrix, classification_report, roc_auc_score)\n\n# Helper function to load processed graphs if already cached, or process and cache them.\ndef load_or_process_graphs(raw_data_path, cache_path='cached_graphs.pt'):\n    if os.path.exists(cache_path):\n        print(\"Loading graphs from cache...\")\n        return torch.load(cache_path)\n    else:\n        print(\"Cache not found. Processing raw data...\")\n        # Replace this with your actual raw data processing logic:\n        # For example, use JetGraphProcessor to process raw files.\n        all_graphs = []\n        # Suppose raw_data_path is a list of NPZ files:\n        for file in raw_data_path:\n            print(f\"Processing file: {file}\")\n            processor = JetGraphProcessor(file)  # Your processing class\n            all_graphs.extend(processor.process_chunk())\n        # Cache the processed graphs.\n        torch.save(all_graphs, cache_path)\n        return all_graphs\n\nclass EnhancedJetGNNTrainer:\n    def __init__(self, model, device, optimizer=None, scheduler=None, lr=1e-3, weight_decay=5e-4, grad_clip=1.0, monitor_metric='accuracy_score'):\n        self.model = model.to(device)\n        self.device = device\n        \n        # Use AdamW optimizer.\n        if optimizer is None:\n            self.optimizer = AdamW(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n        else:\n            self.optimizer = optimizer\n        \n        # Scheduler will be set later if not provided.\n        self.scheduler = scheduler\n        \n        # Use NLLLoss since the model is expected to output log_softmax values.\n        self.criterion = nn.NLLLoss().to(device)\n        \n        # Gradient clipping threshold.\n        self.grad_clip = grad_clip\n        \n        # Monitor metric for saving the best model (e.g., 'f1_score' or 'accuracy').\n        self.monitor_metric = monitor_metric\n\n    def train(self, train_loader, val_loader, num_epochs=50, patience=10, model_save_path='best_jet_gnn_model.pt'):\n        # Initialize CosineAnnealingLR scheduler if not provided.\n        if self.scheduler is None:\n            # T_max is the maximum number of iterations, here we set it to the number of epochs.\n            self.scheduler = CosineAnnealingLR(self.optimizer, T_max=num_epochs)\n        \n        best_metric = -float('inf')\n        wait = 0\n        train_losses = []\n        val_metrics = []\n        \n        for epoch in range(num_epochs):\n            self.model.train()\n            running_loss = 0.0\n            \n            for data in train_loader:\n                data = data.to(self.device)\n                self.optimizer.zero_grad()\n                out = self.model(data)\n                loss = self.criterion(out, data.y.view(-1))\n                loss.backward()\n                \n                # Apply gradient clipping.\n                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.grad_clip)\n                self.optimizer.step()\n                \n                running_loss += loss.item() * data.num_graphs\n\n            # Step the cosine annealing scheduler at the end of the epoch.\n            self.scheduler.step()\n            \n            epoch_train_loss = running_loss / len(train_loader.dataset)\n            metrics = self.evaluate(val_loader)\n            train_losses.append(epoch_train_loss)\n            val_metrics.append(metrics)\n\n            current_lr = self.optimizer.param_groups[0]['lr']\n            print(f\"Epoch [{epoch+1}/{num_epochs}] Train Loss: {epoch_train_loss:.4f} | \"\n                  f\"Val Loss: {metrics['loss']:.4f} | Accuracy: {metrics['accuracy']:.4f} | \"\n                  f\"F1: {metrics['f1_score']:.4f} | AUC: {metrics.get('auc', 0):.4f} | LR: {current_lr:.6f}\")\n\n            # Use the specified monitor metric to track the best model.\n            current_metric = metrics.get(self.monitor_metric, None)\n            if current_metric is None:\n                current_metric = -metrics['loss']  # fallback if metric not available\n\n            if current_metric > best_metric:\n                best_metric = current_metric\n                torch.save(self.model.state_dict(), model_save_path)\n                wait = 0\n            else:\n                wait += 1\n                if wait >= patience:\n                    print(\"Early stopping triggered.\")\n                    break\n\n        self.model.load_state_dict(torch.load(model_save_path))\n        return train_losses, val_metrics\n\n    def evaluate(self, loader):\n        self.model.eval()\n        y_true, y_pred, y_score = [], [], []\n        loss_sum = 0.0\n\n        with torch.no_grad():\n            for data in loader:\n                data = data.to(self.device)\n                out = self.model(data)\n                loss = self.criterion(out, data.y.view(-1))\n                loss_sum += loss.item() * data.num_graphs\n\n                preds = out.argmax(dim=1).cpu().numpy()\n                y_true.extend(data.y.cpu().numpy())\n                y_pred.extend(preds)\n                # For binary classification, extract probability for class 1.\n                y_score.extend(out.exp()[:, 1].cpu().numpy())\n\n        y_true = np.array(y_true)\n        y_pred = np.array(y_pred)\n        y_score = np.array(y_score)\n\n        avg_loss = loss_sum / len(loader.dataset)\n        accuracy = accuracy_score(y_true, y_pred)\n        precision = precision_score(y_true, y_pred, average='macro')\n        recall = recall_score(y_true, y_pred, average='macro')\n        f1 = f1_score(y_true, y_pred, average='macro')\n        conf_matrix = confusion_matrix(y_true, y_pred)\n        class_report = classification_report(y_true, y_pred)\n\n        try:\n            auc = roc_auc_score(y_true, y_score)\n        except Exception:\n            auc = 0.0\n\n        return {\n            \"loss\": avg_loss,\n            \"accuracy\": accuracy,\n            \"precision\": precision,\n            \"recall\": recall,\n            \"f1_score\": f1,\n            \"confusion_matrix\": conf_matrix,\n            \"classification_report\": class_report,\n            \"auc\": auc\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T01:19:43.949943Z","iopub.execute_input":"2025-04-08T01:19:43.950261Z","iopub.status.idle":"2025-04-08T01:19:43.970180Z","shell.execute_reply.started":"2025-04-08T01:19:43.950222Z","shell.execute_reply":"2025-04-08T01:19:43.969472Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T01:19:43.970930Z","iopub.execute_input":"2025-04-08T01:19:43.971141Z","iopub.status.idle":"2025-04-08T01:19:43.988743Z","shell.execute_reply.started":"2025-04-08T01:19:43.971122Z","shell.execute_reply":"2025-04-08T01:19:43.988135Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom torch_geometric.data import DataLoader\nimport gc\n\n# Configuration for training\nconfig = {\n    'chunk_dir': '/kaggle/input/genie-extracted-dataset',  # Directory containing all NPZ chunk files.\n    'chunk_pattern': 'chunk_*.npz',  # Pattern to match chunk files.\n    'batch_size': 16,\n    'hidden_channels': 128,\n    'num_layers': 2,\n    'dropout': 0.4,\n    'learning_rate': 0.001,\n    'weight_decay': 5e-4,\n    'epochs': 10,\n    'patience': 8,\n    'test_size': 0.2,  # 20% of all graphs will be used for testing.\n    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n    'use_dynamic_graph': True,\n    'gat_heads': 4,\n    'use_sagpool': True,\n    'sagpool_ratio': 0.5,\n    'use_non_local': True\n}\n\nprint(f\"Using device: {config['device']}\")\n\n# Helper function to load all chunk files in the specified directory.\ndef get_chunk_files(chunk_dir, pattern):\n    import glob\n    return sorted(glob.glob(os.path.join(chunk_dir, pattern)))\n\n# Updated main() function to train chunk by chunk.\ndef main():\n    # Get all NPZ chunk files.\n    chunk_files = get_chunk_files(config['chunk_dir'], config['chunk_pattern'])\n    print(f\"Found {len(chunk_files)} chunk files.\")\n\n    # Process all chunks once to form the entire dataset for test split.\n    # You may optionally do this offline to obtain indices for test split.\n    all_graphs = []\n    for file in chunk_files:\n        print(f\"Loading chunk: {file}\")\n        processor = JetGraphProcessor(file)  # Your processor to load graphs from NPZ\n        graphs = processor.process_chunk()\n        all_graphs.extend(graphs)\n        # Free memory if necessary:\n        del graphs\n        gc.collect()\n    print(f\"Total graphs processed from all chunks: {len(all_graphs)}\")\n\n    # Create an in-memory dataset from all graphs.\n    dataset = InMemoryJetGraphDataset(all_graphs)\n    print(f\"InMemoryJetGraphDataset created with {len(dataset)} graphs.\")\n\n    # Generate training and test indices.\n    indices = list(range(len(dataset)))\n    labels = torch.tensor([dataset[i].y.item() for i in range(len(dataset))])\n    train_idx, test_idx = train_test_split(indices, test_size=config['test_size'], random_state=42, stratify=labels)\n\n    # Create test dataset and DataLoader (will be used for evaluation every epoch).\n    test_dataset = torch.utils.data.Subset(dataset, test_idx)\n    test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False)\n    print(f\"Test dataset size: {len(test_dataset)}\")\n\n    # We'll train the model epoch-wise by iterating over chunk files.\n    # Initialize the model using a sample graph from the full dataset.\n    sample_data = dataset[0]\n    node_dim = sample_data.x.size(1)\n    global_dim = sample_data.global_features.size(1) if hasattr(sample_data, 'global_features') else 2\n\n    model = EnhancedJetGNN(\n        node_dim=node_dim,\n        global_dim=global_dim,\n        hidden_dim=config['hidden_channels'],\n        out_channels=2,\n        num_layers=config['num_layers'],\n        dropout=config['dropout'],\n        use_dynamic_graph=config['use_dynamic_graph'],\n        heads=config['gat_heads'],\n        use_sagpool=config['use_sagpool'],\n        sagpool_ratio=config['sagpool_ratio'],\n        use_non_local=config['use_non_local']\n    ).to(config['device'])\n\n    # Initialize the trainer.\n    trainer = EnhancedJetGNNTrainer(\n        model=model,\n        device=config['device'],\n        lr=config['learning_rate'],\n        weight_decay=config['weight_decay'],\n    )\n\n    # For early stopping, you can track best performance.\n    best_val_metric = float('inf')\n    epochs_since_improvement = 0\n\n    # Training loop: For each epoch, iterate over each chunk file sequentially.\n    for epoch in range(config['epochs']):\n        model.train()\n        epoch_loss = 0.0\n        num_chunks = 0\n        print(f\"\\nEpoch {epoch+1}/{config['epochs']}\")\n        \n        for chunk_file in chunk_files:\n            print(f\"Processing training chunk: {chunk_file}\")\n            processor = JetGraphProcessor(chunk_file)\n            chunk_graphs = processor.process_chunk()\n            \n            # Create a DataLoader for the current chunk.\n            chunk_dataset = InMemoryJetGraphDataset(chunk_graphs)\n            # Use training indices that are within this chunk.\n            # Note: If each chunk is independent, you can train over the entire chunk.\n            train_loader = DataLoader(chunk_dataset, batch_size=config['batch_size'], shuffle=True)\n            \n            for data in train_loader:\n                data = data.to(config['device'])\n                loss = trainer.train_step(data)  # Assuming trainer has a method train_step(data)\n                epoch_loss += loss.item()\n            \n            # Clear chunk from memory.\n            del chunk_graphs, chunk_dataset, train_loader\n            gc.collect()\n            num_chunks += 1\n        \n        avg_epoch_loss = epoch_loss / num_chunks if num_chunks > 0 else 0\n        print(f\"Epoch {epoch+1} average loss: {avg_epoch_loss:.4f}\")\n        # Evaluate the model on the test set.\n        val_metrics = trainer.evaluate(test_loader)\n        print(f\"Validation metrics: Accuracy: {val_metrics['accuracy']:.4f}, F1: {val_metrics['f1_score']:.4f}\")\n        \n        # Early stopping: If improvement, save model.\n        current_val_metric = val_metrics['f1_score']\n        if current_val_metric < best_val_metric:\n            best_val_metric = current_val_metric\n            epochs_since_improvement = 0\n            torch.save(model.state_dict(), 'best_jet_gnn_model.pt')\n            print(\"Model improved, saving current model.\")\n        else:\n            epochs_since_improvement += 1\n            if epochs_since_improvement >= config['patience']:\n                print(\"No improvement for several epochs, stopping training.\")\n                break\n    \n    # Final evaluation on test set.\n    final_metrics = trainer.evaluate(test_loader)\n    print(\"\\nFinal Test Set Metrics:\")\n    print(f\"Accuracy:  {final_metrics['accuracy']:.4f}\")\n    print(f\"Precision: {final_metrics['precision']:.4f}\")\n    print(f\"Recall:    {final_metrics['recall']:.4f}\")\n    print(f\"F1 Score:  {final_metrics['f1_score']:.4f}\")\n    print(f\"AUC:       {final_metrics['auc']:.4f}\")\n    print(\"Confusion Matrix:\")\n    print(final_metrics['confusion_matrix'])\n    print(\"Classification Report:\")\n    print(final_metrics['classification_report'])\n    \n    # Plotting training loss and validation metrics.\n    import matplotlib.pyplot as plt\n    # Assume trainer has logged train_losses and val metrics history.\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(trainer.train_losses, label='Train Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Training Loss')\n    plt.legend()\n    \n    if trainer.val_metrics_history:\n        epochs_plot = range(1, len(trainer.val_metrics_history) + 1)\n        accuracies = [m['accuracy'] for m in trainer.val_metrics_history]\n        f1_scores = [m['f1_score'] for m in trainer.val_metrics_history]\n        plt.subplot(1, 2, 2)\n        plt.plot(epochs_plot, accuracies, label='Accuracy')\n        plt.plot(epochs_plot, f1_scores, label='F1 Score')\n        plt.xlabel('Epoch')\n        plt.ylabel('Score')\n        plt.title('Validation Metrics')\n        plt.legend()\n    else:\n        print(\"Validation metrics history not available for plotting.\")\n    \n    plt.tight_layout()\n    plt.show()\n\nif __name__ == '__main__':\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T01:20:06.094410Z","iopub.execute_input":"2025-04-08T01:20:06.094703Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nProcessing file: /kaggle/input/chunk_0_10000.npz\n","output_type":"stream"},{"name":"stderr","text":"Processing single chunk:  73%|███████▎  | 7311/10000 [03:07<01:05, 40.81it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}