{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, glob, cv2\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# For deep models (ResNet, DenseNet, etc.)\nimport torchvision.models as models\nimport timm\n\n# For gradient boosting models\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_image_files(folder):\n    return sorted(glob.glob(os.path.join(folder, \"*.*\")))\n\ndef get_chunk(file_list, chunk_index, total_chunks=14):\n    n = len(file_list)\n    chunk_size = n // total_chunks\n    start = chunk_index * chunk_size\n    end = n if chunk_index == total_chunks - 1 else start + chunk_size\n    return file_list[start:end]\n\ndef read_image(path, target_size=(32,32)):\n    img = cv2.imread(path)\n    if img is None:\n        raise FileNotFoundError(f\"Image not found: {path}\")\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, target_size)\n    return img.astype(np.float32) / 255.0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ImageStatsTransform:\n    def __call__(self, x):\n        # x: (C, H, W)\n        mean = x.mean(dim=[1,2], keepdim=True)\n        std = x.std(dim=[1,2], keepdim=True) + 1e-6\n        return (x - mean) / std","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_physics_features_tensor(x, eps=1e-6):\n    # x: (B, 3, H, W); channels represent [ecal, hcal, tracks]\n    ecal = x[:, 0:1, :, :]\n    hcal = x[:, 1:2, :, :]\n    tracks = x[:, 2:3, :, :]\n    ratio = torch.mean(ecal / (hcal + eps), dim=[2,3])\n    mean_tracks = torch.mean(tracks, dim=[2,3])\n    diff = torch.mean(ecal - hcal, dim=[2,3])\n    norm_diff = torch.mean(torch.abs(ecal - hcal) / (ecal + hcal + eps), dim=[2,3])\n    return torch.cat([ratio, mean_tracks, diff, norm_diff], dim=1)  # (B, 4)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ChannelWiseFPN(nn.Module):\n    def __init__(self, in_channels=3, out_channels=16):\n        super(ChannelWiseFPN, self).__init__()\n        self.conv1x1 = nn.Conv2d(1, out_channels, kernel_size=1, padding=0)\n        self.conv3x3 = nn.Conv2d(1, out_channels, kernel_size=3, padding=1)\n        self.conv5x5 = nn.Conv2d(1, out_channels, kernel_size=5, padding=2)\n        self.fuse_conv = nn.Sequential(\n            nn.Conv2d(3*out_channels, out_channels, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(out_channels, out_channels, kernel_size=1)\n        )\n    def forward(self, x):\n        outputs = []\n        for i in range(x.shape[1]):\n            xi = x[:, i:i+1, :, :]\n            feat1 = self.conv1x1(xi)\n            feat2 = self.conv3x3(xi)\n            feat3 = self.conv5x5(xi)\n            cat_feats = torch.cat([feat1, feat2, feat3], dim=1)\n            fused = self.fuse_conv(cat_feats)\n            outputs.append(fused)\n        return torch.cat(outputs, dim=1)  # (B, in_channels*out_channels, H, W)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ResNetWithChannelFPN(nn.Module):\n    def __init__(self, num_classes=2):\n        super(ResNetWithChannelFPN, self).__init__()\n        self.fpn_orig = ChannelWiseFPN(3, 16)\n        self.fpn_diff = ChannelWiseFPN(3, 16)\n        self.fpn_graph = ChannelWiseFPN(3, 16)\n        self.resnet_orig = models.resnet18(pretrained=True)\n        self.resnet_diff = models.resnet18(pretrained=True)\n        self.resnet_graph = models.resnet18(pretrained=True)\n        for branch in [self.resnet_orig, self.resnet_diff, self.resnet_graph]:\n            branch.conv1 = nn.Conv2d(48, 64, kernel_size=7, stride=2, padding=3, bias=False)\n            branch.fc = nn.Identity()  # Output: 512\n        self.classifier = nn.Linear(512 + 4, num_classes)\n    def forward(self, x_orig, x_rec, x_graph):\n        x_diff = x_orig - x_rec\n        feat_orig = self.resnet_orig(self.fpn_orig(x_orig))\n        feat_diff = self.resnet_diff(self.fpn_diff(x_diff))\n        feat_graph = self.resnet_graph(self.fpn_graph(x_graph))\n        deep_feat = (feat_orig + feat_diff + feat_graph) / 3.0\n        phys_feat = compute_physics_features_tensor(x_orig)\n        combined = torch.cat([deep_feat, phys_feat], dim=1)\n        return self.classifier(combined)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DenseNetWithChannelFPN(nn.Module):\n    def __init__(self, num_classes=2):\n        super(DenseNetWithChannelFPN, self).__init__()\n        self.fpn_orig = ChannelWiseFPN(3, 16)\n        self.fpn_diff = ChannelWiseFPN(3, 16)\n        self.fpn_graph = ChannelWiseFPN(3, 16)\n        self.densenet_orig = models.densenet121(pretrained=True)\n        self.densenet_diff = models.densenet121(pretrained=True)\n        self.densenet_graph = models.densenet121(pretrained=True)\n        for net in [self.densenet_orig, self.densenet_diff, self.densenet_graph]:\n            net.features.conv0 = nn.Conv2d(48, 64, kernel_size=7, stride=2, padding=3, bias=False)\n            net.classifier = nn.Identity()  # Output: 1024\n        self.classifier = nn.Linear(1024 + 4, num_classes)\n    def forward(self, x_orig, x_rec, x_graph):\n        x_diff = x_orig - x_rec\n        feat_orig = self.densenet_orig(self.fpn_orig(x_orig))\n        feat_diff = self.densenet_diff(self.fpn_diff(x_diff))\n        feat_graph = self.densenet_graph(self.fpn_graph(x_graph))\n        deep_feat = (feat_orig + feat_diff + feat_graph) / 3.0\n        phys_feat = compute_physics_features_tensor(x_orig)\n        combined = torch.cat([deep_feat, phys_feat], dim=1)\n        return self.classifier(combined)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class EfficientNetWithChannelFPN(nn.Module):\n    def __init__(self, num_classes=2):\n        super(EfficientNetWithChannelFPN, self).__init__()\n        self.fpn_orig = ChannelWiseFPN(3, 16)\n        self.fpn_diff = ChannelWiseFPN(3, 16)\n        self.fpn_graph = ChannelWiseFPN(3, 16)\n        self.effnet_orig = timm.create_model('efficientnet_b0', pretrained=True)\n        self.effnet_diff = timm.create_model('efficientnet_b0', pretrained=True)\n        self.effnet_graph = timm.create_model('efficientnet_b0', pretrained=True)\n        for net in [self.effnet_orig, self.effnet_diff, self.effnet_graph]:\n            net.conv_stem = nn.Conv2d(48, net.conv_stem.out_channels,\n                                        kernel_size=net.conv_stem.kernel_size,\n                                        stride=net.conv_stem.stride,\n                                        padding=net.conv_stem.padding,\n                                        bias=False)\n            net.classifier = nn.Identity()  # Output: 1280\n        self.classifier = nn.Linear(1280 + 4, num_classes)\n    def forward(self, x_orig, x_rec, x_graph):\n        x_diff = x_orig - x_rec\n        feat_orig = self.effnet_orig(self.fpn_orig(x_orig))\n        feat_diff = self.effnet_diff(self.fpn_diff(x_diff))\n        feat_graph = self.effnet_graph(self.fpn_graph(x_graph))\n        deep_feat = (feat_orig + feat_diff + feat_graph) / 3.0\n        phys_feat = compute_physics_features_tensor(x_orig)\n        combined = torch.cat([deep_feat, phys_feat], dim=1)\n        return self.classifier(combined)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ViTWithChannelFPN(nn.Module):\n    def __init__(self, num_classes=2):\n        super(ViTWithChannelFPN, self).__init__()\n        self.fpn_orig = ChannelWiseFPN(3, 16)\n        self.fpn_diff = ChannelWiseFPN(3, 16)\n        self.fpn_graph = ChannelWiseFPN(3, 16)\n        self.vit_orig = timm.create_model('vit_base_patch16_224', pretrained=True)\n        self.vit_diff = timm.create_model('vit_base_patch16_224', pretrained=True)\n        self.vit_graph = timm.create_model('vit_base_patch16_224', pretrained=True)\n        for net in [self.vit_orig, self.vit_diff, self.vit_graph]:\n            net.patch_embed.proj = nn.Conv2d(48, net.patch_embed.proj.out_channels,\n                                             kernel_size=net.patch_embed.proj.kernel_size,\n                                             stride=net.patch_embed.proj.stride,\n                                             padding=net.patch_embed.proj.padding)\n            net.head = nn.Identity()\n        self.classifier = nn.Linear(768 + 4, num_classes)\n    def forward(self, x_orig, x_rec, x_graph):\n        x_diff = x_orig - x_rec\n        feat_orig = self.vit_orig(self.fpn_orig(x_orig))\n        feat_diff = self.vit_diff(self.fpn_diff(x_diff))\n        feat_graph = self.vit_graph(self.fpn_graph(x_graph))\n        deep_feat = (feat_orig + feat_diff + feat_graph) / 3.0\n        phys_feat = compute_physics_features_tensor(x_orig)\n        combined = torch.cat([deep_feat, phys_feat], dim=1)\n        return self.classifier(combined)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SwinWithChannelFPN(nn.Module):\n    def __init__(self, num_classes=2):\n        super(SwinWithChannelFPN, self).__init__()\n        self.fpn_orig = ChannelWiseFPN(3, 16)\n        self.fpn_diff = ChannelWiseFPN(3, 16)\n        self.fpn_graph = ChannelWiseFPN(3, 16)\n        self.swin_orig = timm.create_model('swin_base_patch4_window7_224', pretrained=True)\n        self.swin_diff = timm.create_model('swin_base_patch4_window7_224', pretrained=True)\n        self.swin_graph = timm.create_model('swin_base_patch4_window7_224', pretrained=True)\n        for net in [self.swin_orig, self.swin_diff, self.swin_graph]:\n            net.patch_embed.proj = nn.Conv2d(48, net.patch_embed.proj.out_channels,\n                                             kernel_size=net.patch_embed.proj.kernel_size,\n                                             stride=net.patch_embed.proj.stride,\n                                             padding=net.patch_embed.proj.padding)\n            net.head = nn.Identity()\n        self.classifier = nn.Linear(1024 + 4, num_classes)\n    def forward(self, x_orig, x_rec, x_graph):\n        x_diff = x_orig - x_rec\n        feat_orig = self.swin_orig(self.fpn_orig(x_orig))\n        feat_diff = self.swin_diff(self.fpn_diff(x_diff))\n        feat_graph = self.swin_graph(self.fpn_graph(x_graph))\n        deep_feat = (feat_orig + feat_diff + feat_graph) / 3.0\n        phys_feat = compute_physics_features_tensor(x_orig)\n        combined = torch.cat([deep_feat, phys_feat], dim=1)\n        return self.classifier(combined)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_checkpoint(model, optimizer, filename):\n    if os.path.isfile(filename):\n        checkpoint = torch.load(filename, map_location=\"cpu\")\n        model.load_state_dict(checkpoint[\"model_state\"])\n        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n        print(f\"Loaded checkpoint from {filename} (epoch {checkpoint['epoch']})\")\n    else:\n        print(f\"No checkpoint found at {filename}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TestQuarkGluonDataset(Dataset):\n    def __init__(self, orig_files, rec_files, graph_files, transform=None):\n        self.orig_files = orig_files\n        self.rec_files = rec_files\n        self.graph_files = graph_files\n        self.transform = transform\n    def __len__(self):\n        return len(self.orig_files)\n    def __getitem__(self, idx):\n        orig = read_image(self.orig_files[idx])\n        rec = read_image(self.rec_files[idx])\n        graph = read_image(self.graph_files[idx])\n        orig = torch.tensor(orig).permute(2,0,1)\n        rec = torch.tensor(rec).permute(2,0,1)\n        graph = torch.tensor(graph).permute(2,0,1)\n        if self.transform:\n            orig = self.transform(orig)\n            rec = self.transform(rec)\n            graph = self.transform(graph)\n        return {\"original\": orig, \"reconstructed\": rec, \"graph\": graph}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_deep_ensemble_predictions(model_list, dataloader, device):\n    model_preds = []\n    with torch.no_grad():\n        for model in model_list:\n            model.eval()\n            preds = []\n            for batch in dataloader:\n                x_orig = batch[\"original\"].to(device)\n                x_rec = batch[\"reconstructed\"].to(device)\n                x_graph = batch[\"graph\"].to(device)\n                outputs = torch.softmax(model(x_orig, x_rec, x_graph), dim=1)[:,1]  # probability of class 1\n                preds.append(outputs.cpu().numpy())\n            model_preds.append(np.concatenate(preds))\n    # Average predictions across models\n    deep_ensemble = np.mean(np.stack(model_preds, axis=0), axis=0)\n    return deep_ensemble","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def main_final():\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    transform = ImageStatsTransform()\n    \n    # Update folder paths based on new structure.\n    orig_folder = \"/kaggle/input/genie-extracted-dataset\"\n    rec_folders = [\n        \"/kaggle/input/genie-output-part-1/reconstructions\",\n        \"/kaggle/input/genie-common-task-1-output-part-2final/reconstructions\"\n    ]\n    graph_folders = [\n        \"/kaggle/input/common-task-2-dataset-part-1/processed_jet_graphs\",\n        \"/kaggle/input/output-part-2-of-task-2/processed_jet_graphs\",\n        \"/kaggle/input/output-part-3-of-task-2/processed_jet_graphs\",\n        \"/kaggle/input/part-4-task-2-output/processed_jet_graphs\"\n    ]\n    \n    # Load original image files.\n    orig_files = get_image_files(orig_folder)\n    \n    # Gather reconstructed files from both parts.\n    rec_files = []\n    for folder in rec_folders:\n        rec_files.extend(get_image_files(folder))\n    \n    # Gather graph files from all parts, filtering out specified files.\n    graph_files = []\n    for folder in graph_folders:\n        files = get_image_files(folder)\n        ignore_files = []\n        if \"common-task-2-dataset-part-1\" in folder:\n            ignore_files.append(\"processed_chunk_120000_130000.pt\")\n        if \"output-part-2-of-task-2\" in folder:\n            ignore_files.append(\"processed_chunk_40000_50000.pt\")\n        if \"output-part-3-of-task-2\" in folder:\n            ignore_files.append(\"processed_chunk_80000_90000.pt\")\n        filtered = [f for f in files if os.path.basename(f) not in ignore_files]\n        graph_files.extend(filtered)\n    \n    # Create the test dataset and dataloader.\n    test_dataset = TestQuarkGluonDataset(orig_files, rec_files, graph_files, transform=transform)\n    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)\n    \n    # Instantiate all five deep models and load their checkpoints.\n    resnet_model = ResNetWithChannelFPN(num_classes=2).to(device)\n    dense_model  = DenseNetWithChannelFPN(num_classes=2).to(device)\n    effnet_model = EfficientNetWithChannelFPN(num_classes=2).to(device)\n    vit_model    = ViTWithChannelFPN(num_classes=2).to(device)\n    swin_model   = SwinWithChannelFPN(num_classes=2).to(device)\n    \n    # Dummy optimizer for checkpoint loading.\n    optimizer = optim.Adam(resnet_model.parameters(), lr=1e-4)\n    load_checkpoint(resnet_model, optimizer, \"resnet_checkpoint.pth\")\n    load_checkpoint(dense_model, optimizer, \"dense_checkpoint.pth\")\n    load_checkpoint(effnet_model, optimizer, \"effnet_checkpoint.pth\")\n    load_checkpoint(vit_model, optimizer, \"vit_checkpoint.pth\")\n    load_checkpoint(swin_model, optimizer, \"swin_checkpoint.pth\")\n    \n    deep_models = [resnet_model, dense_model, effnet_model, vit_model, swin_model]\n    deep_preds = get_deep_ensemble_predictions(deep_models, test_loader, device)\n    \n    # -------------------------------\n    # Merge Deep Predictions with Metadata\n    # -------------------------------\n    # Load metadata (must contain sample_id, n0, pt, label, etc.)\n    meta_df = pd.read_csv(\"/kaggle/input/metadata/metadata.csv\")\n    # Assume the order of images in meta_df corresponds to the order in the test dataset.\n    meta_df[\"deep_ensemble_pred\"] = deep_preds\n    \n    # Engineer additional meta features.\n    meta_df[\"n0_pt_ratio\"] = meta_df[\"n0\"] / (meta_df[\"pt\"] + 1e-6)\n    meta_df[\"n0_plus_pt\"] = meta_df[\"n0\"] + meta_df[\"pt\"]\n    deep_cols = [\"deep_ensemble_pred\"]\n    meta_df[\"meta_deep_avg\"] = meta_df[deep_cols].mean(axis=1)\n    \n    # -------------------------------\n    # Train Diverse Gradient Boosting Models on Meta Data\n    # -------------------------------\n    # Features used: deep ensemble prediction, n0, pt, and engineered features.\n    features = [\"deep_ensemble_pred\", \"n0\", \"pt\", \"n0_pt_ratio\", \"n0_plus_pt\", \"meta_deep_avg\"]\n    target = \"label\"  # Must exist in meta_df.\n    \n    X = meta_df[features]\n    y = meta_df[target]\n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n    \n    # Train XGBoost.\n    xgb_model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n    xgb_model.fit(X_train, y_train)\n    xgb_preds = xgb_model.predict_proba(X_val)[:, 1]\n    \n    # Train CatBoost (suppress output).\n    cat_model = CatBoostClassifier(silent=True, random_state=42)\n    cat_model.fit(X_train, y_train)\n    cat_preds = cat_model.predict_proba(X_val)[:, 1]\n    \n    # Train Histogram-based Gradient Boosting.\n    hist_model = HistGradientBoostingClassifier(random_state=42)\n    hist_model.fit(X_train, y_train)\n    hist_preds = hist_model.predict_proba(X_val)[:, 1]\n    \n    # Ensemble the GBT predictions (average).\n    gbt_ensemble_val = (xgb_preds + cat_preds + hist_preds) / 3.0\n    print(\"Validation Accuracy of GBT Ensemble:\",\n          accuracy_score(y_val, (gbt_ensemble_val > 0.5).astype(int)))\n    \n    # Predict on the full meta data using the three models and average.\n    xgb_full = xgb_model.predict_proba(X)[:, 1]\n    cat_full = cat_model.predict_proba(X)[:, 1]\n    hist_full = hist_model.predict_proba(X)[:, 1]\n    gbt_ensemble_full = (xgb_full + cat_full + hist_full) / 3.0\n    \n    # -------------------------------\n    # Final Ensemble: Average Deep Ensemble and GBT Ensemble Predictions\n    # -------------------------------\n    meta_df[\"final_pred_prob\"] = (meta_df[\"deep_ensemble_pred\"] + gbt_ensemble_full) / 2.0\n    meta_df[\"final_prediction\"] = (meta_df[\"final_pred_prob\"] > 0.5).astype(int)\n    \n    # Save final predictions.\n    meta_df.to_csv(\"final_ensemble_predictions.csv\", index=False)\n    print(\"Final ensemble predictions saved to final_ensemble_predictions.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    main_final()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
