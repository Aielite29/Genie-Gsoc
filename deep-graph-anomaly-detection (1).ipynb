{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11151123,"sourceType":"datasetVersion","datasetId":6957107},{"sourceId":11241329,"sourceType":"datasetVersion","datasetId":7023321}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch_geometric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T23:18:40.216546Z","iopub.execute_input":"2025-04-07T23:18:40.216853Z","iopub.status.idle":"2025-04-07T23:18:43.707392Z","shell.execute_reply.started":"2025-04-07T23:18:40.216832Z","shell.execute_reply":"2025-04-07T23:18:43.706490Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.12)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.12.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.18.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2025.1.31)\nRequirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch_geometric) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torch_geometric) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torch_geometric) (2024.2.0)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GATConv, global_mean_pool, global_max_pool\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import StepLR\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score\nfrom sklearn.model_selection import train_test_split\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T23:23:37.965522Z","iopub.execute_input":"2025-04-07T23:23:37.965831Z","iopub.status.idle":"2025-04-07T23:23:37.971450Z","shell.execute_reply.started":"2025-04-07T23:23:37.965811Z","shell.execute_reply":"2025-04-07T23:23:37.970562Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"class JetGraphDataset(torch.utils.data.Dataset):\n    def __init__(self, graph_path, npz_path):\n        \"\"\"\n        Loads graphs from a .pt file and corresponding physics features from an npz file.\n        Each graph is augmented with:\n            - y: label (quark/gluon)\n            - pt: normalized transverse momentum\n            - m0: normalized jet mass\n            - explosion: ratio of number of edges to number of nodes (physics-inspired)\n        \"\"\"\n        super(JetGraphDataset, self).__init__()\n        self.graphs = torch.load(graph_path, map_location=device)\n        \n        data_npz = np.load(npz_path)\n        self.labels = data_npz['y']      # Quark/Gluon labels (as integers)\n        self.pt = data_npz['pt']         # Transverse momentum\n        self.m0 = data_npz['m0']         # Jet mass\n        \n        # Normalize physics features\n        self.pt = (self.pt - np.mean(self.pt)) / (np.std(self.pt) + 1e-8)\n        self.m0 = (self.m0 - np.mean(self.m0)) / (np.std(self.m0) + 1e-8)\n        \n        for i, graph in enumerate(self.graphs):\n            graph.y = torch.tensor([int(self.labels[i])], dtype=torch.long, device=device)\n            graph.pt = torch.tensor([self.pt[i]], dtype=torch.float, device=device)\n            graph.m0 = torch.tensor([self.m0[i]], dtype=torch.float, device=device)\n            # If no node features, initialize with ones\n            if not hasattr(graph, 'x') or graph.x is None:\n                # If not provided, default feature dimension is set to 16.\n                graph.x = torch.ones((graph.num_nodes, 16), device=device)\n            # Compute explosion metric: number of edges / number of nodes\n            num_edges = graph.edge_index.size(1) if hasattr(graph, 'edge_index') else 0\n            explosion = num_edges / graph.num_nodes if graph.num_nodes > 0 else 0.0\n            graph.explosion = torch.tensor([explosion], dtype=torch.float, device=device)\n    \n    def __len__(self):\n        return len(self.graphs)\n    \n    def __getitem__(self, idx):\n        return self.graphs[idx]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T23:27:23.643336Z","iopub.execute_input":"2025-04-07T23:27:23.643685Z","iopub.status.idle":"2025-04-07T23:27:23.651025Z","shell.execute_reply.started":"2025-04-07T23:27:23.643659Z","shell.execute_reply":"2025-04-07T23:27:23.650261Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"class EnhancedGATEncoder(nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, heads=4, dropout=0.2):\n        super(EnhancedGATEncoder, self).__init__()\n        self.dropout = dropout\n        # GAT layers with LayerNorm\n        self.gat1 = GATConv(in_channels, hidden_channels, heads=heads, concat=True)\n        self.ln1 = nn.LayerNorm(hidden_channels * heads)\n        self.gat2 = GATConv(hidden_channels * heads, hidden_channels, heads=heads, concat=True)\n        self.ln2 = nn.LayerNorm(hidden_channels * heads)\n        self.gat3 = GATConv(hidden_channels * heads, out_channels, heads=1, concat=False)\n        self.ln3 = nn.LayerNorm(out_channels)\n        # Skip connection: project input to out_channels with adaptive gating\n        self.skip_proj = nn.Linear(in_channels, out_channels)\n        self.gate = nn.Sequential(nn.Linear(out_channels * 2, out_channels), nn.Sigmoid())\n        # Optional spectral branch: a simple linear transformation for multi-frequency filtering\n        self.spectral_linear = nn.Linear(in_channels, out_channels)\n    \n    def forward(self, x, edge_index, batch):\n        # GAT pathway with dropout and LayerNorm\n        out1 = F.elu(self.ln1(self.gat1(x, edge_index)))\n        out1 = F.dropout(out1, p=self.dropout, training=self.training)\n        out2 = F.elu(self.ln2(self.gat2(out1, edge_index)))\n        out2 = F.dropout(out2, p=self.dropout, training=self.training)\n        out3 = self.ln3(self.gat3(out2, edge_index))\n        # Skip connection\n        skip = self.skip_proj(x)\n        combined_main = out3 + skip\n        gate_factor = self.gate(torch.cat([out3, skip], dim=-1))\n        gated = gate_factor * combined_main\n        \n        # Multi-scale pooling: fuse mean and max pooling\n        pooled_mean = global_mean_pool(gated, batch)\n        pooled_max = global_max_pool(gated, batch)\n        pooled_main = torch.cat([pooled_mean, pooled_max], dim=-1)\n        # Project multi-scale pooled embedding back to out_channels (use a linear layer)\n        proj_layer = nn.Linear(pooled_main.shape[-1], skip.shape[-1]).to(x.device)\n        pooled_main = torch.tanh(proj_layer(pooled_main))\n        \n        # Spectral branch: compute a spectral transformation (linear approximation)\n        spectral_out = self.spectral_linear(x)\n        pooled_spectral = global_mean_pool(spectral_out, batch)\n        \n        # Fuse both branches\n        fused = pooled_main + pooled_spectral\n        return fused\n\nclass ProjectionHead(nn.Module):\n    def __init__(self, in_dim, proj_dim):\n        super(ProjectionHead, self).__init__()\n        self.fc1 = nn.Linear(in_dim, proj_dim)\n        self.fc2 = nn.Linear(proj_dim, proj_dim)\n    \n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\n# Modified AuxiliaryReconstructionHead to output target dimension equal to original node feature dimension.\nclass AuxiliaryReconstructionHead(nn.Module):\n    def __init__(self, in_dim, recon_dim, target_dim):\n        \"\"\"\n        Reconstruct aggregated node features as an auxiliary task.\n        Args:\n            in_dim: dimension of the encoder output.\n            recon_dim: hidden dimension for reconstruction.\n            target_dim: target dimension to reconstruct (should equal original node feature dimension).\n        \"\"\"\n        super(AuxiliaryReconstructionHead, self).__init__()\n        self.fc1 = nn.Linear(in_dim, recon_dim)\n        self.fc2 = nn.Linear(recon_dim, target_dim)\n    \n    def forward(self, z):\n        z_rec = F.relu(self.fc1(z))\n        z_rec = self.fc2(z_rec)\n        return z_rec\n\nclass ClassifierHead(nn.Module):\n    def __init__(self, in_dim, num_classes):\n        super(ClassifierHead, self).__init__()\n        self.fc1 = nn.Linear(in_dim, in_dim // 2)\n        self.fc2 = nn.Linear(in_dim // 2, num_classes)\n    \n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        logits = self.fc2(x)\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T23:27:37.884358Z","iopub.execute_input":"2025-04-07T23:27:37.884641Z","iopub.status.idle":"2025-04-07T23:27:37.895839Z","shell.execute_reply.started":"2025-04-07T23:27:37.884621Z","shell.execute_reply":"2025-04-07T23:27:37.894893Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"class EnhancedGraphModel(nn.Module):\n    def __init__(self, in_channels, hidden_channels, encoder_out, proj_dim, num_classes, use_aux_recon=True):\n        super(EnhancedGraphModel, self).__init__()\n        self.encoder = EnhancedGATEncoder(in_channels, hidden_channels, encoder_out)\n        self.projection_head = ProjectionHead(encoder_out, proj_dim)\n        self.use_aux_recon = use_aux_recon\n        if self.use_aux_recon:\n            # Reconstruction head: output dimension equals original node feature dimension (in_channels)\n            self.reconstruction_head = AuxiliaryReconstructionHead(encoder_out, encoder_out // 2, target_dim=in_channels)\n        # Classifier: concatenates graph embedding with physics features (pt, m0, explosion)\n        self.classifier = ClassifierHead(encoder_out + 3, num_classes)\n        self.classifier_dropout = nn.Dropout(0.2)\n    \n    def forward(self, data, mode='contrastive'):\n        # data: a Batch from PyG containing x, edge_index, batch, pt, m0, explosion\n        x = data.x\n        edge_index = data.edge_index\n        batch = data.batch\n        embedding = self.encoder(x, edge_index, batch)\n        \n        if mode == 'contrastive':\n            proj = self.projection_head(embedding)\n            if self.use_aux_recon:\n                rec = self.reconstruction_head(embedding)\n                return proj, rec, embedding\n            return proj, None, embedding\n        elif mode == 'classification':\n            if hasattr(data, 'pt') and hasattr(data, 'm0') and hasattr(data, 'explosion'):\n                physics_features = torch.cat([\n                    data.pt.view(-1, 1),\n                    data.m0.view(-1, 1),\n                    data.explosion.view(-1, 1)\n                ], dim=1)\n                embedding = torch.cat([embedding, physics_features], dim=1)\n            embedding = self.classifier_dropout(embedding)\n            logits = self.classifier(embedding)\n            return logits\n        else:\n            raise ValueError(\"Mode must be 'contrastive' or 'classification'.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T23:27:49.513862Z","iopub.execute_input":"2025-04-07T23:27:49.514196Z","iopub.status.idle":"2025-04-07T23:27:49.521058Z","shell.execute_reply.started":"2025-04-07T23:27:49.514166Z","shell.execute_reply":"2025-04-07T23:27:49.520200Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"def improved_nt_xent_loss(z1, z2, temperature=0.5, margin=0.5, lambda_reg=0.1):\n    \"\"\"\n    NT-Xent loss with hard negative margin regularization.\n    \"\"\"\n    batch_size = z1.shape[0]\n    z = torch.cat([z1, z2], dim=0)\n    z = F.normalize(z, dim=1)\n    \n    similarity_matrix = torch.matmul(z, z.T)\n    mask = torch.eye(2 * batch_size, dtype=torch.bool, device=z.device)\n    similarity_matrix = similarity_matrix.masked_fill(mask, -9e15)\n    similarity_matrix = similarity_matrix / temperature\n    \n    labels = torch.arange(batch_size, device=z.device)\n    labels = torch.cat([labels, labels], dim=0)\n    nt_xent = F.cross_entropy(similarity_matrix, labels)\n    \n    negatives = similarity_matrix.clone()\n    negatives[mask] = -9e15\n    max_negatives, _ = negatives.max(dim=1)\n    margin_loss = F.relu(max_negatives - margin).mean()\n    \n    total_loss = nt_xent + lambda_reg * margin_loss\n    return total_loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T23:28:18.698835Z","iopub.execute_input":"2025-04-07T23:28:18.699186Z","iopub.status.idle":"2025-04-07T23:28:18.704721Z","shell.execute_reply.started":"2025-04-07T23:28:18.699161Z","shell.execute_reply":"2025-04-07T23:28:18.703889Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"class EnhancedTrainer:\n    def __init__(self, model, train_loader, test_loader, device, lr=1e-3, lambda_aux=0.5):\n        self.model = model.to(device)\n        self.train_loader = train_loader\n        self.test_loader = test_loader\n        self.device = device\n        self.optimizer = Adam(self.model.parameters(), lr=lr)\n        self.scheduler = StepLR(self.optimizer, step_size=5, gamma=0.5)\n        self.criterion_cls = nn.CrossEntropyLoss()\n        self.criterion_rec = nn.MSELoss()\n        self.lambda_aux = lambda_aux  # Weight for auxiliary reconstruction loss\n    \n    def pretrain(self, epochs, drop_prob=0.2, edge_perturb_prob=0.1, temperature=0.5, margin=0.5, lambda_reg=0.1):\n        self.model.train()\n        for epoch in range(epochs):\n            total_loss = 0.0\n            for data in self.train_loader:\n                data = data.to(self.device)\n                if not hasattr(data, 'x') or data.x is None:\n                    data.x = torch.ones((data.num_nodes, 16), device=self.device)\n                \n                # Generate two augmented views:\n                # View 1: Node dropout + edge perturbation\n                data1 = self._graph_augmentation(data, drop_prob, edge_perturb_prob)\n                # View 2: Feature masking augmentation (zero out a fraction of node features)\n                data2 = self._feature_mask_augmentation(data, mask_prob=0.2)\n                data1 = data1.to(self.device)\n                data2 = data2.to(self.device)\n                \n                self.optimizer.zero_grad()\n                proj1, rec1, _ = self.model(data1, mode='contrastive')\n                proj2, rec2, _ = self.model(data2, mode='contrastive')\n                \n                # Contrastive loss on projections\n                loss_contrast = improved_nt_xent_loss(proj1, proj2, temperature, margin, lambda_reg)\n                \n                # Auxiliary reconstruction loss:\n                # Use global mean pooling of the original node features as target.\n                pooled1 = global_mean_pool(data1.x, data1.batch)\n                pooled2 = global_mean_pool(data2.x, data2.batch)\n                loss_rec1 = self.criterion_rec(rec1, pooled1)\n                loss_rec2 = self.criterion_rec(rec2, pooled2)\n                loss_rec = (loss_rec1 + loss_rec2) / 2.0\n                \n                total_loss_batch = loss_contrast + self.lambda_aux * loss_rec\n                \n                # Optional: Add adversarial loss for robustness (currently commented)\n                # total_loss_batch += 0.01 * self._adversarial_loss(data)\n                \n                total_loss_batch.backward()\n                self.optimizer.step()\n                total_loss += total_loss_batch.item()\n            self.scheduler.step()\n            avg_loss = total_loss / len(self.train_loader)\n            print(f\"[Pretrain] Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f}, LR: {self.optimizer.param_groups[0]['lr']:.6f}\")\n    \n    def finetune(self, epochs, freeze_encoder=True, early_stop_patience=5):\n        if freeze_encoder:\n            for param in self.model.encoder.parameters():\n                param.requires_grad = False\n        \n        optimizer_cls = Adam(self.model.classifier.parameters(), lr=1e-3)\n        scheduler_cls = StepLR(optimizer_cls, step_size=5, gamma=0.5)\n        \n        best_loss = float('inf')\n        patience_counter = 0\n        \n        self.model.train()\n        for epoch in range(epochs):\n            total_loss = 0.0\n            for data in self.train_loader:\n                data = data.to(self.device)\n                if not hasattr(data, 'x') or data.x is None:\n                    data.x = torch.ones((data.num_nodes, 16), device=self.device)\n                optimizer_cls.zero_grad()\n                logits = self.model(data, mode='classification')\n                loss = self.criterion_cls(logits, data.y)\n                loss.backward()\n                optimizer_cls.step()\n                total_loss += loss.item()\n            scheduler_cls.step()\n            avg_loss = total_loss / len(self.train_loader)\n            metrics = self.evaluate()\n            print(f\"[Finetune] Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f}, Accuracy: {metrics['accuracy']*100:.2f}%, \"\n                  f\"F1: {metrics['f1']:.4f}, ROC-AUC: {metrics['roc_auc']:.4f}, LR: {optimizer_cls.param_groups[0]['lr']:.6f}\")\n            if avg_loss < best_loss:\n                best_loss = avg_loss\n                patience_counter = 0\n                # Optionally save checkpoint here\n            else:\n                patience_counter += 1\n                if patience_counter >= early_stop_patience:\n                    print(f\"Early stopping triggered at epoch {epoch+1}\")\n                    break\n    \n    def evaluate(self):\n        self.model.eval()\n        all_preds, all_labels, all_probs = [], [], []\n        with torch.no_grad():\n            for data in self.test_loader:\n                data = data.to(self.device)\n                if not hasattr(data, 'x') or data.x is None:\n                    data.x = torch.ones((data.num_nodes, 16), device=self.device)\n                logits = self.model(data, mode='classification')\n                probs = F.softmax(logits, dim=1)[:, 1]\n                preds = logits.argmax(dim=1).cpu().numpy()\n                all_preds.extend(preds)\n                all_probs.extend(probs.cpu().numpy())\n                all_labels.extend(data.y.cpu().numpy())\n        acc = accuracy_score(all_labels, all_preds)\n        f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n        try:\n            roc_auc = roc_auc_score(all_labels, all_probs)\n        except Exception:\n            roc_auc = 0.0\n        self.model.train()\n        return {\"accuracy\": acc, \"f1\": f1, \"roc_auc\": roc_auc}\n    \n    def _graph_augmentation(self, data, drop_prob, edge_perturb_prob):\n        \"\"\"\n        Apply node dropout and stochastic edge perturbation.\n        \"\"\"\n        node_mask = torch.rand(data.num_nodes, device=data.x.device) > drop_prob\n        if node_mask.sum() == 0:\n            node_mask[torch.randint(0, data.num_nodes, (1,))] = True\n        new_idx = torch.zeros(data.num_nodes, dtype=torch.long, device=data.x.device)\n        new_idx[node_mask] = torch.arange(node_mask.sum(), device=data.x.device)\n        x = data.x[node_mask]\n        edge_index = data.edge_index\n        mask = node_mask[edge_index[0]] & node_mask[edge_index[1]]\n        edge_index = edge_index[:, mask]\n        edge_index = new_idx[edge_index]\n        if edge_index.size(1) > 0:\n            edge_drop_mask = torch.rand(edge_index.size(1), device=edge_index.device) > edge_perturb_prob\n            edge_index = edge_index[:, edge_drop_mask]\n        new_data = Data(x=x, edge_index=edge_index)\n        if hasattr(data, 'batch'):\n            new_data.batch = data.batch[node_mask]\n        if hasattr(data, 'pt'):\n            new_data.pt = data.pt\n        if hasattr(data, 'm0'):\n            new_data.m0 = data.m0\n        if hasattr(data, 'explosion'):\n            new_data.explosion = data.explosion\n        return new_data\n    \n    def _feature_mask_augmentation(self, data, mask_prob=0.2):\n        \"\"\"\n        Augment graphs by masking a fraction of node features.\n        \"\"\"\n        new_data = Data()\n        new_data.x = data.x.clone()\n        mask = torch.rand(data.x.size(0), device=data.x.device) < mask_prob\n        new_data.x[mask] = 0.0  # Zero out selected features\n        new_data.edge_index = data.edge_index\n        new_data.batch = data.batch\n        if hasattr(data, 'pt'): new_data.pt = data.pt\n        if hasattr(data, 'm0'): new_data.m0 = data.m0\n        if hasattr(data, 'explosion'): new_data.explosion = data.explosion\n        return new_data\n    \n    def _adversarial_loss(self, data, epsilon=0.01):\n        \"\"\"\n        Compute a simple adversarial perturbation loss.\n        Adds Gaussian noise to node features to simulate worst-case perturbation.\n        \"\"\"\n        perturbed_x = data.x + epsilon * torch.randn_like(data.x)\n        adv_data = Data(x=perturbed_x, edge_index=data.edge_index, batch=data.batch)\n        adv_proj, _, _ = self.model(adv_data, mode='contrastive')\n        orig_proj, _, _ = self.model(data, mode='contrastive')\n        return F.mse_loss(adv_proj, orig_proj)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T23:28:42.135304Z","iopub.execute_input":"2025-04-07T23:28:42.135613Z","iopub.status.idle":"2025-04-07T23:28:42.160123Z","shell.execute_reply.started":"2025-04-07T23:28:42.135590Z","shell.execute_reply":"2025-04-07T23:28:42.159136Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"graph_path = '/kaggle/input/part-4-task-2-output/processed_jet_graphs/processed_chunk_90000_100000.pt'\nnpz_path = '/kaggle/input/genie-extracted-dataset/chunk_90000_100000.npz'\n\n# Create dataset\ndataset = JetGraphDataset(graph_path, npz_path)\n\n# Split dataset indices using stratification on labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T23:28:44.365600Z","iopub.execute_input":"2025-04-07T23:28:44.365890Z","iopub.status.idle":"2025-04-07T23:29:02.688820Z","shell.execute_reply.started":"2025-04-07T23:28:44.365870Z","shell.execute_reply":"2025-04-07T23:29:02.688131Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-31-73326252bd2d>:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  self.graphs = torch.load(graph_path, map_location=device)\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"indices = np.arange(len(dataset))\nlabels = np.array([dataset[i].y.item() for i in range(len(dataset))])\ntrain_idx, test_idx = train_test_split(indices, test_size=0.1, random_state=42, stratify=labels)\n\ntrain_graphs = [dataset[i] for i in train_idx]\ntest_graphs = [dataset[i] for i in test_idx]\n\nprint(f\"Total graphs: {len(dataset)}; Training graphs: {len(train_graphs)}; Testing graphs: {len(test_graphs)}\")\n\nbatch_size = 256\ntrain_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_graphs, batch_size=batch_size, shuffle=False)\n\nin_channels = train_graphs[0].x.shape[1]\nhidden_channels = 64\nencoder_out = 64\nproj_dim = 32\nnum_classes = 2\n\n# Instantiate the EnhancedGraphModel\nmodel = EnhancedGraphModel(in_channels, hidden_channels, encoder_out, proj_dim, num_classes, use_aux_recon=True)\ntrainer = EnhancedTrainer(model, train_loader, test_loader, device, lr=1e-3, lambda_aux=0.5)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T23:42:53.838359Z","iopub.execute_input":"2025-04-07T23:42:53.838754Z","iopub.status.idle":"2025-04-07T23:42:53.991220Z","shell.execute_reply.started":"2025-04-07T23:42:53.838731Z","shell.execute_reply":"2025-04-07T23:42:53.990200Z"}},"outputs":[{"name":"stdout","text":"Total graphs: 10000; Training graphs: 9000; Testing graphs: 1000\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n  warnings.warn(out)\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"pretrain_epochs = 10  # Adjust as necessary\nprint(\"Starting contrastive pre-training...\")\ntrainer.pretrain(epochs=pretrain_epochs, drop_prob=0.1, temperature=0.7, margin=0.3, lambda_reg=0.4\n                )\n\n# %% [markdown]\n# ### 6.2 Classification Fine-tuning\n# \n# Fine-tune the classifier for anomaly detection/classification. Metrics are computed after each epoch.\n\n# %%\nfinetune_epochs = 20  # Adjust as necessary\nprint(\"\\nStarting classification fine-tuning...\")\ntrainer.finetune(epochs=finetune_epochs, freeze_encoder=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T23:43:04.509980Z","iopub.execute_input":"2025-04-07T23:43:04.510345Z","iopub.status.idle":"2025-04-07T23:43:04.749623Z","shell.execute_reply.started":"2025-04-07T23:43:04.510319Z","shell.execute_reply":"2025-04-07T23:43:04.748287Z"}},"outputs":[{"name":"stdout","text":"Starting contrastive pre-training...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n  warnings.warn(message)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-f61463d36f3f>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpretrain_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m  \u001b[0;31m# Adjust as necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting contrastive pre-training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m trainer.pretrain(epochs=pretrain_epochs, drop_prob=0.1, temperature=0.7, margin=0.3, lambda_reg=0.4\n\u001b[0m\u001b[1;32m      4\u001b[0m                 )\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-37-e9c4fd3cf0c2>\u001b[0m in \u001b[0;36mpretrain\u001b[0;34m(self, epochs, drop_prob, edge_perturb_prob, temperature, margin, lambda_reg)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mproj1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'contrastive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0mproj2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'contrastive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;31m# Contrastive loss on projections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-33-148dfe118e3c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data, mode)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'contrastive'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-32-36f3709e5c0a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mout1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgat1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mout1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mout2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgat2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mout2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mout3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgat3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/gat_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;31m# propagate_type: (x: OptPairTensor, alpha: Tensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/torch_geometric.nn.conv.gat_conv_GATConv_propagate_hdpuqe8f.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, alpha, size)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         kwargs = self.collect(\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/torch_geometric.nn.conv.gat_conv_GATConv_propagate_hdpuqe8f.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self, edge_index, x, alpha, size)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_x_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_x_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mx_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_x_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index_j\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mx_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36m_index_select\u001b[0;34m(self, src, index)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_select_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_index_select_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36m_index_select_safe\u001b[0;34m(self, src, index)\u001b[0m\n\u001b[1;32m    288\u001b[0m                     f\"your node feature matrix and try again.\")\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     def _lift(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36m_index_select_safe\u001b[0;34m(self, src, index)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_index_select_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 728.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 589.12 MiB is free. Process 4668 has 15.31 GiB memory in use. Of the allocated memory 14.49 GiB is allocated by PyTorch, and 540.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 728.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 589.12 MiB is free. Process 4668 has 15.31 GiB memory in use. Of the allocated memory 14.49 GiB is allocated by PyTorch, and 540.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}],"execution_count":44},{"cell_type":"code","source":"final_metrics = trainer.evaluate()\nprint(\"Final Evaluation Metrics:\")\nprint(f\"Accuracy: {final_metrics['accuracy']*100:.2f}%\")\nprint(f\"F1 Score: {final_metrics['f1']:.4f}\")\nprint(f\"ROC-AUC: {final_metrics['roc_auc']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T23:38:42.529667Z","iopub.execute_input":"2025-04-07T23:38:42.530038Z","iopub.status.idle":"2025-04-07T23:38:43.147310Z","shell.execute_reply.started":"2025-04-07T23:38:42.530015Z","shell.execute_reply":"2025-04-07T23:38:43.146396Z"}},"outputs":[{"name":"stdout","text":"Final Evaluation Metrics:\nAccuracy: 66.60%\nF1 Score: 0.6658\nROC-AUC: 0.7196\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"finetune_epochs = 10  # Adjust as necessary\nprint(\"\\nStarting classification fine-tuning...\")\ntrainer.finetune(epochs=finetune_epochs, freeze_encoder=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}