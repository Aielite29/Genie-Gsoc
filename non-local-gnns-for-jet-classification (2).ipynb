{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11151123,"sourceType":"datasetVersion","datasetId":6957107}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch_geometric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T00:25:40.235207Z","iopub.execute_input":"2025-04-08T00:25:40.235497Z","iopub.status.idle":"2025-04-08T00:25:45.448696Z","shell.execute_reply.started":"2025-04-08T00:25:40.235477Z","shell.execute_reply":"2025-04-08T00:25:45.447858Z"}},"outputs":[{"name":"stdout","text":"Collecting torch_geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.12)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.12.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.18.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2025.1.31)\nRequirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch_geometric) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torch_geometric) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torch_geometric) (2024.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch_geometric\nSuccessfully installed torch_geometric-2.6.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport re\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch_geometric.data import Data\nfrom torch_geometric.nn import (\n    global_mean_pool, global_max_pool, global_add_pool,\n    GATConv, EdgeConv, SAGPooling\n)\nfrom torch_geometric.nn.conv import MessagePassing\nfrom torch_geometric.transforms import BaseTransform\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import (accuracy_score, precision_score, recall_score,\n                             f1_score, confusion_matrix, classification_report, roc_auc_score)\nfrom torch.optim import SGD\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T00:26:25.955974Z","iopub.execute_input":"2025-04-08T00:26:25.956487Z","iopub.status.idle":"2025-04-08T00:26:25.961992Z","shell.execute_reply.started":"2025-04-08T00:26:25.956459Z","shell.execute_reply":"2025-04-08T00:26:25.961246Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def extract_chunk_numbers(f):\n    m = re.search(r'chunk_(\\d+)_(\\d+)', f)\n    if m:\n        return (int(m.group(1)), int(m.group(2)))\n    else:\n        return (float('inf'), float('inf'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T00:26:27.133563Z","iopub.execute_input":"2025-04-08T00:26:27.133890Z","iopub.status.idle":"2025-04-08T00:26:27.137951Z","shell.execute_reply.started":"2025-04-08T00:26:27.133862Z","shell.execute_reply":"2025-04-08T00:26:27.137121Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class RandomPhiShift(BaseTransform):\n    def __init__(self, dphi=0.2):\n        self.dphi = dphi\n    \n    def __call__(self, data):\n        if data.pos.size(0) > 0:\n            shift = (torch.rand(1) * 2 - 1) * self.dphi\n            data.pos[:, 1] = data.pos[:, 1] + shift\n            data.pos[:, 1] = torch.atan2(torch.sin(data.pos[:, 1]), torch.cos(data.pos[:, 1]))\n        return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T00:26:28.012587Z","iopub.execute_input":"2025-04-08T00:26:28.012879Z","iopub.status.idle":"2025-04-08T00:26:28.018369Z","shell.execute_reply.started":"2025-04-08T00:26:28.012858Z","shell.execute_reply":"2025-04-08T00:26:28.017201Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class DynamicHybridGraph(nn.Module):\n    def __init__(self, k=4, alpha=0.5, beta=0.5):\n        super().__init__()\n        self.k = k\n        self.alpha = alpha\n        self.beta = beta\n        \n    def forward(self, x, pos, batch):\n        device = x.device\n        batch_size = batch.max().item() + 1\n        edge_index_list = []\n        edge_attr_list = []\n        \n        for i in range(batch_size):\n            mask = (batch == i)\n            x_batch = x[mask]\n            pos_batch = pos[mask]\n            if x_batch.size(0) <= 1:\n                continue\n            \n            # Compute distances\n            dist_geom = torch.cdist(pos_batch, pos_batch)\n            dist_feat = torch.cdist(x_batch, x_batch)\n            dist_combined = self.alpha * dist_geom + self.beta * dist_feat\n            \n            k_eff = min(self.k + 1, x_batch.size(0))\n            _, topk_indices = torch.topk(dist_combined, k=k_eff, largest=False, dim=1)\n            topk_indices = topk_indices[:, 1:]  # remove self-loop\n            \n            rows = torch.arange(x_batch.size(0), device=device).view(-1, 1).repeat(1, k_eff-1)\n            offset = mask.nonzero(as_tuple=True)[0].min().item()\n            edge_index = torch.stack([rows.reshape(-1), topk_indices.reshape(-1)], dim=0) + offset\n            \n            source_nodes = edge_index[0] - offset\n            target_nodes = edge_index[1] - offset\n            delta_eta = pos_batch[target_nodes, 0] - pos_batch[source_nodes, 0]\n            delta_phi = pos_batch[target_nodes, 1] - pos_batch[source_nodes, 1]\n            delta_phi = torch.atan2(torch.sin(delta_phi), torch.cos(delta_phi))\n            delta_r = torch.sqrt(delta_eta**2 + delta_phi**2)\n            delta_embed = x_batch[target_nodes] - x_batch[source_nodes]\n            delta_embed_norm = torch.norm(delta_embed, p=2, dim=1, keepdim=True)\n            edge_attr = torch.cat([\n                delta_eta.unsqueeze(1),\n                delta_phi.unsqueeze(1),\n                delta_r.unsqueeze(1),\n                delta_embed_norm\n            ], dim=1)\n            \n            edge_index_list.append(edge_index)\n            edge_attr_list.append(edge_attr)\n        \n        if not edge_index_list:\n            return (torch.zeros((2, 0), device=device, dtype=torch.long),\n                    torch.zeros((0, 4), device=device))\n        edge_index = torch.cat(edge_index_list, dim=1)\n        edge_attr = torch.cat(edge_attr_list, dim=0)\n        return edge_index, edge_attr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T00:26:28.330794Z","iopub.execute_input":"2025-04-08T00:26:28.331062Z","iopub.status.idle":"2025-04-08T00:26:28.340373Z","shell.execute_reply.started":"2025-04-08T00:26:28.331037Z","shell.execute_reply":"2025-04-08T00:26:28.339531Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def create_multiscale_knn(pos, k1=4, k2=6):\n    def knn_graph(pos, k):\n        n = pos.size(0)\n        if n <= 1:\n            return torch.zeros((2, 0), dtype=torch.long), torch.zeros((0, 3), dtype=torch.float)\n        dist = torch.cdist(pos, pos)\n        _, nn_idx = torch.topk(dist, k=min(k+1, n), dim=1, largest=False)\n        nn_idx = nn_idx[:, 1:]\n        rows = torch.arange(n).view(-1, 1).repeat(1, min(k, n-1))\n        edge_index = torch.stack([rows.reshape(-1), nn_idx.reshape(-1)], dim=0)\n        source_nodes = edge_index[0]\n        target_nodes = edge_index[1]\n        delta_eta = pos[target_nodes, 0] - pos[source_nodes, 0]\n        delta_phi = pos[target_nodes, 1] - pos[source_nodes, 1]\n        delta_phi = torch.atan2(torch.sin(delta_phi), torch.cos(delta_phi))\n        delta_r = torch.sqrt(delta_eta**2 + delta_phi**2)\n        edge_attr = torch.stack([delta_eta, delta_phi, delta_r], dim=1)\n        return edge_index, edge_attr\n    eidx_s, eattr_s = knn_graph(pos, k1)\n    eidx_l, eattr_l = knn_graph(pos, k2)\n    return eidx_s, eattr_s, eidx_l, eattr_l","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T00:26:28.511498Z","iopub.execute_input":"2025-04-08T00:26:28.511745Z","iopub.status.idle":"2025-04-08T00:26:28.517850Z","shell.execute_reply.started":"2025-04-08T00:26:28.511720Z","shell.execute_reply":"2025-04-08T00:26:28.517189Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class JetGraphProcessor:\n    def __init__(self, input_dir, transform=None, k=8, min_energy_threshold=1e-4):\n        self.input_dir = input_dir\n        self.transform = transform\n        self.k = k\n        self.min_energy_threshold = min_energy_threshold\n    \n    def _convert_to_graph(self, jet_image, label, m0, pt):\n        \"\"\"\n        Convert a jet image (3D numpy array) into a PyG Data object.\n        Assumes jet_image shape is (H, W, C).\n        \"\"\"\n        # Sum across channels to form a 2D projection\n        jet_image_2d = np.sum(jet_image, axis=2)\n        padded = np.pad(jet_image_2d, pad_width=1, mode='constant', constant_values=0)\n        non_zero_indices = np.where(jet_image_2d > self.min_energy_threshold)\n        points = []\n        features = []\n        for i, j in zip(non_zero_indices[0], non_zero_indices[1]):\n            pixel_eta = (i / 125.0 * 2 - 1) * 0.8\n            pixel_phi = (j / 125.0 * 2 - 1) * 0.8\n            energy_ecal = jet_image[i, j, 0]\n            energy_hcal = jet_image[i, j, 1]\n            energy_tracks = jet_image[i, j, 2]\n            total_energy = energy_ecal + energy_hcal + energy_tracks\n            pt_fraction = total_energy / (pt + 1e-9)\n            charged_fraction = energy_tracks / total_energy if total_energy > 0 else 0.0\n            local_sum = np.sum(padded[i:i+3, j:j+3])\n            angle_center = np.arctan2(j - 62.5, i - 62.5)\n            norm_dist_center = np.sqrt((i - 62.5)**2 + (j - 62.5)**2) / 62.5\n            features.append([\n                total_energy, energy_ecal, energy_hcal, energy_tracks,\n                pt_fraction, charged_fraction, local_sum,\n                pixel_eta, pixel_phi, np.log1p(total_energy),\n                np.sqrt(total_energy), angle_center, norm_dist_center\n            ])\n            points.append([pixel_eta, pixel_phi])\n        if len(points) == 0:\n            points = [[0, 0]]\n            features = [[0.0]*13]\n        x = torch.tensor(features, dtype=torch.float)\n        pos = torch.tensor(points, dtype=torch.float)\n        eidx_s, eattr_s, eidx_l, eattr_l = create_multiscale_knn(pos, k1=8, k2=16)\n        data = Data(\n            x=x,\n            pos=pos,\n            edge_index=eidx_s,\n            edge_attr=eattr_s,\n            y=torch.tensor([label], dtype=torch.long)\n        )\n        data.edge_index_large = eidx_l\n        data.edge_attr_large = eattr_l\n        data.global_features = torch.tensor([m0, pt], dtype=torch.float).unsqueeze(0)\n        return data\n    \n    def process_all_chunks(self):\n        \"\"\"\n        Process all .npz files from input_dir and accumulate graphs in memory.\n        \"\"\"\n        all_chunk_files = sorted(\n            [f for f in os.listdir(self.input_dir) if f.endswith('.npz')],\n            key=extract_chunk_numbers\n        )\n        all_graphs = []\n        for chunk_file in all_chunk_files:\n            print(f\"Processing {chunk_file} ...\")\n            data_npz = np.load(os.path.join(self.input_dir, chunk_file))\n            X_jets = data_npz['X_jets']\n            if 'y' in data_npz:\n                y = data_npz['y']\n            else:\n                raise KeyError(\"Label key 'y' not found in the dataset.\")\n            m0 = data_npz['m0']\n            pt = data_npz['pt']\n            for i in tqdm(range(X_jets.shape[0]), desc=f\"Processing {chunk_file}\"):\n                graph = self._convert_to_graph(X_jets[i], int(y[i]), m0[i], pt[i])\n                if self.transform:\n                    graph = self.transform(graph)\n                all_graphs.append(graph)\n        print(f\"Total graphs processed: {len(all_graphs)}\")\n        return all_graphs\n\n    def process_chunk(self):\n        \"\"\"\n        Process a single NPZ file (input_file) and return a list of graphs.\n        \"\"\"\n        data_npz = np.load(self.input_dir)  # here, input_dir is actually the file path\n        X_jets = data_npz['X_jets']\n        y = data_npz['y']\n        m0 = data_npz['m0']\n        pt = data_npz['pt']\n        all_graphs = []\n        for i in tqdm(range(X_jets.shape[0]), desc=\"Processing single chunk\"):\n            graph = self._convert_to_graph(X_jets[i], int(y[i]), m0[i], pt[i])\n            if self.transform:\n                graph = self.transform(graph)\n            all_graphs.append(graph)\n        return all_graphs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T00:26:31.157757Z","iopub.execute_input":"2025-04-08T00:26:31.158048Z","iopub.status.idle":"2025-04-08T00:26:31.170993Z","shell.execute_reply.started":"2025-04-08T00:26:31.158026Z","shell.execute_reply":"2025-04-08T00:26:31.170214Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class BatchNorm(nn.Module):\n    def __init__(self, num_features):\n        super().__init__()\n        self.bn = nn.BatchNorm1d(num_features)\n    \n    def forward(self, x):\n        return self.bn(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T00:26:32.865420Z","iopub.execute_input":"2025-04-08T00:26:32.865717Z","iopub.status.idle":"2025-04-08T00:26:32.870257Z","shell.execute_reply.started":"2025-04-08T00:26:32.865695Z","shell.execute_reply":"2025-04-08T00:26:32.869375Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class InMemoryJetGraphDataset(Dataset):\n    def __init__(self, graphs, transform=None):\n        self.graphs = graphs\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.graphs)\n    \n    def __getitem__(self, idx):\n        graph = self.graphs[idx]\n        if self.transform:\n            graph = self.transform(graph)\n        return graph","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T00:26:33.025427Z","iopub.execute_input":"2025-04-08T00:26:33.025666Z","iopub.status.idle":"2025-04-08T00:26:33.029983Z","shell.execute_reply.started":"2025-04-08T00:26:33.025646Z","shell.execute_reply":"2025-04-08T00:26:33.029202Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class CoordinateEmbedding(nn.Module):\n    def __init__(self, in_dim=2, out_dim=4):\n        super().__init__()\n        self.mlp = nn.Sequential(\n            nn.Linear(in_dim, out_dim),\n            nn.ReLU(),\n            nn.Linear(out_dim, out_dim)\n        )\n    \n    def forward(self, coords):\n        return self.mlp(coords)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T00:26:33.626414Z","iopub.execute_input":"2025-04-08T00:26:33.626960Z","iopub.status.idle":"2025-04-08T00:26:33.633498Z","shell.execute_reply.started":"2025-04-08T00:26:33.626914Z","shell.execute_reply":"2025-04-08T00:26:33.632665Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class NonLocalBlock(nn.Module):\n    \"\"\"\n    A non-local block for self-attention over the nodes.\n    Adapted from 'Non-local Neural Networks', with a simplified design.\n    \"\"\"\n    def __init__(self, in_channels, inter_channels=None, bn_layer=True):\n        super().__init__()\n        self.in_channels = in_channels\n        if inter_channels is None:\n            inter_channels = in_channels // 2\n            if inter_channels == 0:\n                inter_channels = 1\n        self.inter_channels = inter_channels\n\n        # Theta, Phi, and g are 1x1 convolutions (pointwise fully connected layers)\n        self.theta = nn.Conv1d(in_channels, inter_channels, kernel_size=1, bias=False)\n        self.phi   = nn.Conv1d(in_channels, inter_channels, kernel_size=1, bias=False)\n        self.g     = nn.Conv1d(in_channels, inter_channels, kernel_size=1, bias=False)\n        self.W     = nn.Conv1d(inter_channels, in_channels, kernel_size=1, bias=False)\n        if bn_layer:\n            self.bn = nn.BatchNorm1d(in_channels)\n        else:\n            self.bn = None\n\n    def forward(self, x):\n        # x: (N, C) where N is the number of nodes, C is the number of channels.\n        N, C = x.shape\n        # Reshape to (1, C, N) to apply 1D convolutions over the \"spatial\"/node dimension.\n        x_reshaped = x.transpose(0, 1).unsqueeze(0)  # shape: (1, C, N)\n\n        theta_x = self.theta(x_reshaped)  # (1, inter_channels, N)\n        phi_x   = self.phi(x_reshaped)    # (1, inter_channels, N)\n        g_x     = self.g(x_reshaped)      # (1, inter_channels, N)\n\n        # Reshape theta_x and phi_x for the attention computation.\n        theta_x = theta_x.squeeze(0).transpose(0, 1)  # shape: (N, inter_channels)\n        phi_x = phi_x.squeeze(0)                      # shape: (inter_channels, N)\n        f = torch.matmul(theta_x, phi_x)              # shape: (N, N)\n        f_div_C = f / f.shape[-1]                     # normalization\n        \n        # g_x reshaped: (N, inter_channels)\n        g_x = g_x.squeeze(0).transpose(0, 1)\n        y = torch.matmul(f_div_C, g_x)                # shape: (N, inter_channels)\n        # Return to shape (1, inter_channels, N), then apply W and (optionally) batch norm.\n        y = y.transpose(0, 1).unsqueeze(0)\n        W_y = self.W(y)\n        if self.bn is not None:\n            W_y = self.bn(W_y)\n        # Residual connection: add the input x (reshaped back to (N, C))\n        z = W_y.squeeze(0).transpose(0, 1) + x\n        return z","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T00:26:35.100750Z","iopub.execute_input":"2025-04-08T00:26:35.101071Z","iopub.status.idle":"2025-04-08T00:26:35.108327Z","shell.execute_reply.started":"2025-04-08T00:26:35.101042Z","shell.execute_reply":"2025-04-08T00:26:35.107482Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class EnhancedJetGNN(nn.Module):\n    def __init__(self, node_dim, global_dim, hidden_dim=64, out_channels=2, \n                 num_layers=3, dropout=0.3, use_dynamic_graph=True, heads=4, \n                 use_sagpool=True, sagpool_ratio=0.5, use_non_local=False, use_sageconv=True):\n        super().__init__()\n        self.node_dim = node_dim\n        self.global_dim = global_dim\n        self.hidden_dim = hidden_dim\n        self.num_layers = num_layers\n        self.dropout = dropout\n        self.use_dynamic_graph = use_dynamic_graph\n        self.heads = heads\n        self.use_sagpool = use_sagpool\n        self.sagpool_ratio = sagpool_ratio\n        self.use_non_local = use_non_local\n        self.use_sageconv = use_sageconv\n        \n        # Coordinate embedding for (η, φ) at indices 7 and 8\n        self.coord_embed = CoordinateEmbedding(in_dim=2, out_dim=4)\n        # Process the remaining node features\n        self.feature_mlp = nn.Sequential(\n            nn.Linear(node_dim - 2, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, hidden_dim)\n        )\n        # Combine coordinate embedding with processed features\n        self.comb_mlp = nn.Sequential(\n            nn.Linear(hidden_dim + 4, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU()\n        )\n        # Global feature encoder\n        self.global_encoder = nn.Sequential(\n            nn.Linear(global_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU()\n        )\n        # Dynamic adjacency module\n        if use_dynamic_graph:\n            self.dynamic_graph = DynamicHybridGraph(k=8, alpha=0.5, beta=0.5)\n        # GNN layers (alternating GAT and EdgeConv)\n        self.gnn_layers = nn.ModuleList()\n        self.batch_norms = nn.ModuleList()\n        self.gnn_layers.append(\n            GATConv(hidden_dim, hidden_dim // heads, heads=heads, edge_dim=4, dropout=dropout)\n        )\n        self.batch_norms.append(BatchNorm(hidden_dim))\n        for i in range(1, num_layers):\n            if i % 2 == 1:\n                self.gnn_layers.append(\n                    EdgeConv(\n                        nn=nn.Sequential(\n                            nn.Linear(hidden_dim*2, hidden_dim),\n                            nn.ReLU(),\n                            nn.Dropout(dropout),\n                            nn.Linear(hidden_dim, hidden_dim)\n                        ),\n                        aggr='mean'\n                    )\n                )\n            else:\n                self.gnn_layers.append(\n                    GATConv(hidden_dim, hidden_dim // heads, heads=heads, edge_dim=4, dropout=dropout)\n                )\n            self.batch_norms.append(BatchNorm(hidden_dim))\n        \n        # SAGEConv branch (if enabled)\n        if self.use_sageconv:\n            self.sage_layers = nn.ModuleList()\n            for i in range(num_layers):\n                self.sage_layers.append(SAGEConv(hidden_dim, hidden_dim, aggr='mean'))\n        \n        # Insert a non-local block if enabled.\n        if self.use_non_local:\n            self.non_local = NonLocalBlock(in_channels=hidden_dim)\n        \n        # Optional SAGPooling for hierarchical pooling\n        if self.use_sagpool:\n            self.sagpool = SAGPooling(hidden_dim, ratio=self.sagpool_ratio)\n        \n        # Final classifier: multi-scale pooling (mean, max, sum) combined with global features.\n        # Note: After pooling, pooled features have dimension hidden_dim.\n        # Global encoder output is hidden_dim, so total input = 3*hidden_dim + hidden_dim = 4*hidden_dim.\n        self.classifier = nn.Sequential(\n            nn.Linear(4 * hidden_dim, 2 * hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(2 * hidden_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, out_channels)\n        )\n    \n    def forward(self, data):\n        # data.x shape: (num_nodes, node_dim)\n        # data.batch: (num_nodes,)\n        # data.edge_index: (2, num_edges)\n        # data.edge_attr: (num_edges, 4), assume edge features of size 4\n        x, batch = data.x, data.batch\n        edge_index, edge_attr = data.edge_index, data.edge_attr\n        pos = data.pos\n        if hasattr(data, 'global_features'):\n            global_features = data.global_features\n        else:\n            global_features = torch.zeros((batch.max().item()+1, self.global_dim), device=x.device)\n        if batch is None:\n            batch = torch.zeros(x.size(0), dtype=torch.long, device=x.device)\n        \n        # Process node features: separate coordinate features at indices 7 and 8.\n        coords = x[:, [7, 8]]\n        other_feats = torch.cat([x[:, :7], x[:, 9:]], dim=1)\n        coord_emb = self.coord_embed(coords)\n        feat_emb = self.feature_mlp(other_feats)\n        x_initial = torch.cat([feat_emb, coord_emb], dim=1)\n        x_initial = self.comb_mlp(x_initial)  # Now x_initial has shape (num_nodes, hidden_dim)\n        global_x = self.global_encoder(global_features)  # (num_graphs, hidden_dim)\n        \n        # Apply dynamic adjacency if enabled.\n        if self.use_dynamic_graph:\n            edge_index, edge_attr = self.dynamic_graph(x_initial, pos, batch)\n        \n        # GNN branch\n        x_gnn = x_initial\n        for i, conv in enumerate(self.gnn_layers):\n            if self.use_dynamic_graph:\n                edge_index, edge_attr = self.dynamic_graph(x_gnn, pos, batch)\n            if isinstance(conv, GATConv):\n                x_gnn = conv(x_gnn, edge_index, edge_attr=edge_attr)\n            else:\n                x_gnn = conv(x_gnn, edge_index)\n            x_gnn = self.batch_norms[i](x_gnn)\n            x_gnn = F.relu(x_gnn)\n            x_gnn = F.dropout(x_gnn, p=self.dropout, training=self.training)\n        \n        # SAGEConv branch (if enabled)\n        if self.use_sageconv:\n            x_sage = x_initial\n            for sage in self.sage_layers:\n                x_sage = sage(x_sage, edge_index)\n                x_sage = F.relu(x_sage)\n                x_sage = F.dropout(x_sage, p=self.dropout, training=self.training)\n            # Fuse outputs (average)\n            x = (x_gnn + x_sage) / 2.0\n        else:\n            x = x_gnn\n        \n        # Apply non-local block if enabled\n        if self.use_non_local:\n            x = self.non_local(x)\n        \n        # Apply SAGPooling if enabled\n        if self.use_sagpool:\n            x, edge_index, edge_attr, batch, _, _ = self.sagpool(x, edge_index, edge_attr, batch=batch)\n        \n        pooled_mean = global_mean_pool(x, batch)\n        pooled_max = global_max_pool(x, batch)\n        pooled_sum = global_add_pool(x, batch)\n        \n        combined = torch.cat([pooled_mean, pooled_max, pooled_sum, global_x], dim=1)\n        out = self.classifier(combined)\n        return F.log_softmax(out, dim=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T00:27:03.170438Z","iopub.execute_input":"2025-04-08T00:27:03.170760Z","iopub.status.idle":"2025-04-08T00:27:03.185270Z","shell.execute_reply.started":"2025-04-08T00:27:03.170733Z","shell.execute_reply":"2025-04-08T00:27:03.184392Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def visualize_graph(graph, ax=None):\n    if ax is None:\n        fig, ax = plt.subplots()\n    pos = graph.pos.numpy()\n    ax.scatter(pos[:, 0], pos[:, 1], c='blue', s=30, label='Nodes')\n    # Plot edges\n    if graph.edge_index.size(1) > 0:\n        edge_index = graph.edge_index.numpy()\n        for i in range(edge_index.shape[1]):\n            src = pos[edge_index[0, i]]\n            dst = pos[edge_index[1, i]]\n            ax.plot([src[0], dst[0]], [src[1], dst[1]], c='gray', linewidth=0.5)\n    ax.set_title(f\"Graph (Label: {graph.y.item()})\")\n    ax.legend()\n    return ax","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T00:27:27.620733Z","iopub.execute_input":"2025-04-08T00:27:27.621012Z","iopub.status.idle":"2025-04-08T00:27:27.626335Z","shell.execute_reply.started":"2025-04-08T00:27:27.620991Z","shell.execute_reply":"2025-04-08T00:27:27.625450Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"from torch_geometric.data import Data, InMemoryDataset\nfrom torch_geometric.loader import DataLoader\n\nimport torch\nimport torch.nn as nn\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score\nfrom torch.optim import SGD\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n\nclass EnhancedJetGNNTrainer:\n    def __init__(self, model, device, optimizer=None, scheduler=None, lr=1e-2, weight_decay=5e-4):\n        self.model = model.to(device)\n        self.device = device\n        \n        # Use SGD with momentum as the optimizer.\n        if optimizer is None:\n            self.optimizer = SGD(self.model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n        else:\n            self.optimizer = optimizer\n        \n        # Scheduler: CosineAnnealingWarmRestarts with T_0=5.\n        self.scheduler = scheduler if scheduler is not None else CosineAnnealingWarmRestarts(self.optimizer, T_0=5, T_mult=1)\n        \n        # Use NLLLoss since the model outputs log_softmax.\n        self.criterion = nn.NLLLoss().to(device)\n\n    def train(self, train_loader, val_loader, num_epochs=50, patience=10, model_save_path='best_jet_gnn_model.pt'):\n        best_val_loss = float('inf')\n        wait = 0\n        train_losses = []\n        val_metrics = []\n\n        for epoch in range(num_epochs):\n            self.model.train()\n            running_loss = 0.0\n            for data in train_loader:\n                data = data.to(self.device)\n                self.optimizer.zero_grad()\n                out = self.model(data)\n                loss = self.criterion(out, data.y.view(-1))\n                loss.backward()\n                self.optimizer.step()\n                running_loss += loss.item() * data.num_graphs\n\n            epoch_train_loss = running_loss / len(train_loader.dataset)\n            metrics = self.evaluate(val_loader)\n            train_losses.append(epoch_train_loss)\n            val_metrics.append(metrics)\n\n            print(f\"Epoch [{epoch+1}/{num_epochs}] Train Loss: {epoch_train_loss:.4f} | \"\n                  f\"Val Loss: {metrics['loss']:.4f} | Accuracy: {metrics['accuracy']:.4f} | \"\n                  f\"F1: {metrics['f1_score']:.4f} | AUC: {metrics.get('auc', 0):.4f}\")\n\n            if self.scheduler is not None:\n                self.scheduler.step()\n\n            if metrics['loss'] < best_val_loss:\n                best_val_loss = metrics['loss']\n                torch.save(self.model.state_dict(), model_save_path)\n                wait = 0\n            else:\n                wait += 1\n                if wait >= patience:\n                    print(\"Early stopping triggered.\")\n                    break\n\n        self.model.load_state_dict(torch.load(model_save_path))\n        return train_losses, val_metrics\n\n    def evaluate(self, loader):\n        self.model.eval()\n        y_true, y_pred, y_score = [], [], []\n        loss_sum = 0.0\n\n        with torch.no_grad():\n            for data in loader:\n                data = data.to(self.device)\n                out = self.model(data)\n                loss = self.criterion(out, data.y.view(-1))\n                loss_sum += loss.item() * data.num_graphs\n\n                preds = out.argmax(dim=1).cpu().numpy()\n                y_true.extend(data.y.cpu().numpy())\n                y_pred.extend(preds)\n                # For binary classification, extract probability for class 1.\n                y_score.extend(out.exp()[:, 1].cpu().numpy())\n\n        y_true = np.array(y_true)\n        y_pred = np.array(y_pred)\n        y_score = np.array(y_score)\n\n        avg_loss = loss_sum / len(loader.dataset)\n        accuracy = accuracy_score(y_true, y_pred)\n        precision = precision_score(y_true, y_pred, average='macro')\n        recall = recall_score(y_true, y_pred, average='macro')\n        f1 = f1_score(y_true, y_pred, average='macro')\n        conf_matrix = confusion_matrix(y_true, y_pred)\n        class_report = classification_report(y_true, y_pred)\n\n        try:\n            auc = roc_auc_score(y_true, y_score)\n        except Exception:\n            auc = 0.0\n\n        return {\n            \"loss\": avg_loss,\n            \"accuracy\": accuracy,\n            \"precision\": precision,\n            \"recall\": recall,\n            \"f1_score\": f1,\n            \"confusion_matrix\": conf_matrix,\n            \"classification_report\": class_report,\n            \"auc\": auc\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T00:27:24.887155Z","iopub.execute_input":"2025-04-08T00:27:24.887464Z","iopub.status.idle":"2025-04-08T00:27:24.900351Z","shell.execute_reply.started":"2025-04-08T00:27:24.887442Z","shell.execute_reply":"2025-04-08T00:27:24.899323Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T11:23:49.128022Z","iopub.execute_input":"2025-04-05T11:23:49.128351Z","iopub.status.idle":"2025-04-05T11:23:49.150805Z","shell.execute_reply.started":"2025-04-05T11:23:49.128323Z","shell.execute_reply":"2025-04-05T11:23:49.150102Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def main():\n    # Configuration: Toggle 'use_non_local' to switch between baseline and non-local GNN.\n    config = {\n        'chunk_files': [\n            '/kaggle/input/chunk_0_10000.npz',\n            '/kaggle/input/chunk_10000_20000.npz',\n        ],\n        'batch_size': 16,\n        'hidden_channels': 128,\n        'num_layers': 2,\n        'dropout': 0.4,\n        'learning_rate': 0.001,\n        'weight_decay': 5e-4,\n        'epochs': 10,\n        'patience': 8,\n        'test_size': 0.2,  # 20% for test/inference\n        'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n        'use_dynamic_graph': True,\n        'gat_heads': 4,\n        'use_sagpool': True,\n        'sagpool_ratio': 0.5,\n        # Set to True to use the non-local GNN variant.\n        'use_non_local': True\n    }\n\n    print(f\"Using device: {config['device']}\")\n\n    # Process multiple NPZ files into graphs.\n    all_graphs = []\n    for file in config['chunk_files']:\n        print(f\"Processing file: {file}\")\n        processor = JetGraphProcessor(file)\n        all_graphs.extend(processor.process_chunk())\n    print(f\"Total graphs processed: {len(all_graphs)}\")\n\n    # Create an in-memory dataset.\n    dataset = InMemoryJetGraphDataset(all_graphs)\n    print(f\"InMemoryJetGraphDataset created with {len(dataset)} graphs.\")\n\n    # Split dataset indices for train (80%) and test (20%).\n    indices = list(range(len(dataset)))\n    train_idx, test_idx = train_test_split(indices, test_size=config['test_size'], random_state=42)\n\n    train_dataset = torch.utils.data.Subset(dataset, train_idx)\n    test_dataset = torch.utils.data.Subset(dataset, test_idx)\n\n    print(f\"Train size: {len(train_dataset)}\")\n    print(f\"Test size:  {len(test_dataset)}\")\n\n    # Use PyTorch Geometric DataLoader for batching Data objects.\n    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n    test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False)\n\n    # Determine feature dimensions from a sample graph.\n    sample_data = dataset[0]\n    node_dim = sample_data.x.size(1)\n    global_dim = sample_data.global_features.size(1) if hasattr(sample_data, 'global_features') else 2\n\n    # Initialize the model.\n    model = EnhancedJetGNN(\n        node_dim=node_dim,\n        global_dim=global_dim,\n        hidden_dim=config['hidden_channels'],\n        out_channels=2,\n        num_layers=config['num_layers'],\n        dropout=config['dropout'],\n        use_dynamic_graph=config['use_dynamic_graph'],\n        heads=config['gat_heads'],\n        use_sagpool=config['use_sagpool'],\n        sagpool_ratio=config['sagpool_ratio'],\n        use_non_local=config['use_non_local']\n    ).to(config['device'])\n\n    # Initialize the trainer.\n    trainer = EnhancedJetGNNTrainer(\n        model=model,\n        device=config['device'],\n        lr=config['learning_rate'],\n        weight_decay=config['weight_decay'],\n    )\n\n    # Train the model using the training loader and validate on the test loader.\n    train_losses, test_metrics_history = trainer.train(\n        train_loader=train_loader,\n        val_loader=test_loader,  # Using test set for validation in this example.\n        num_epochs=config['epochs'],\n        patience=config['patience'],\n        model_save_path='best_jet_gnn_model.pt'\n    )\n\n    # Evaluate on the test set and print final metrics.\n    final_test_metrics = trainer.evaluate(test_loader)\n    print(\"\\nTest Set Metrics:\")\n    print(f\"Accuracy:  {final_test_metrics['accuracy']:.4f}\")\n    print(f\"Precision: {final_test_metrics['precision']:.4f}\")\n    print(f\"Recall:    {final_test_metrics['recall']:.4f}\")\n    print(f\"F1 Score:  {final_test_metrics['f1_score']:.4f}\")\n    print(f\"AUC:       {final_test_metrics['auc']:.4f}\")\n    print(\"Confusion Matrix:\")\n    print(final_test_metrics['confusion_matrix'])\n    print(\"Classification Report:\")\n    print(final_test_metrics['classification_report'])\n\n    # Plot training loss and validation metrics.\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(train_losses, label='Train Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Training Loss')\n    plt.legend()\n\n    if test_metrics_history:\n        epochs = range(1, len(test_metrics_history) + 1)\n        accuracies = [m['accuracy'] for m in test_metrics_history]\n        f1_scores = [m['f1_score'] for m in test_metrics_history]\n        plt.subplot(1, 2, 2)\n        plt.plot(epochs, accuracies, label='Accuracy')\n        plt.plot(epochs, f1_scores, label='F1 Score')\n        plt.xlabel('Epoch')\n        plt.ylabel('Score')\n        plt.title('Validation Metrics')\n        plt.legend()\n    else:\n        print(\"Test metrics history is not available for plotting.\")\n\n    plt.tight_layout()\n    plt.show()\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T00:46:55.501237Z","iopub.execute_input":"2025-04-08T00:46:55.501560Z","execution_failed":"2025-04-08T00:47:04.735Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nProcessing file: /kaggle/input/chunk_0_10000.npz\n","output_type":"stream"},{"name":"stderr","text":"Processing single chunk:   0%|          | 4/10000 [00:00<04:18, 38.69it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}