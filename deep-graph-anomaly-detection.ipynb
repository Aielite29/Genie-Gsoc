{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11151123,"sourceType":"datasetVersion","datasetId":6957107},{"sourceId":11241329,"sourceType":"datasetVersion","datasetId":7023321}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch_geometric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T22:26:13.899402Z","iopub.execute_input":"2025-04-07T22:26:13.899844Z","iopub.status.idle":"2025-04-07T22:26:17.330903Z","shell.execute_reply.started":"2025-04-07T22:26:13.899794Z","shell.execute_reply":"2025-04-07T22:26:17.329744Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.12)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.12.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.18.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2025.1.31)\nRequirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch_geometric) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torch_geometric) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torch_geometric) (2024.2.0)\n","output_type":"stream"}],"execution_count":74},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.nn import GATConv, global_mean_pool\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import StepLR\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score\nfrom sklearn.model_selection import train_test_split\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T22:26:17.332416Z","iopub.execute_input":"2025-04-07T22:26:17.332740Z","iopub.status.idle":"2025-04-07T22:26:17.339157Z","shell.execute_reply.started":"2025-04-07T22:26:17.332707Z","shell.execute_reply":"2025-04-07T22:26:17.338197Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":75},{"cell_type":"code","source":"class JetGraphDataset(torch.utils.data.Dataset):\n    def __init__(self, graph_path, npz_path):\n        \"\"\"\n        Args:\n            graph_path (str): Path to the processed graphs (.pt file).\n            npz_path (str): Path to the corresponding npz file containing physics features.\n        \"\"\"\n        super(JetGraphDataset, self).__init__()\n        self.graphs = torch.load(graph_path, map_location=device)\n        \n        data_npz = np.load(npz_path)\n        self.labels = data_npz['y']      # Quark/Gluon labels (converted to int)\n        self.pt = data_npz['pt']         # Transverse momentum\n        self.m0 = data_npz['m0']         # Jet mass\n        \n        for i, graph in enumerate(self.graphs):\n            # Assign basic physics features\n            graph.y = torch.tensor([int(self.labels[i])], dtype=torch.long, device=device)\n            graph.pt = torch.tensor([self.pt[i]], dtype=torch.float, device=device)\n            graph.m0 = torch.tensor([self.m0[i]], dtype=torch.float, device=device)\n            # If no node features exist, initialize them\n            if not hasattr(graph, 'x') or graph.x is None:\n                graph.x = torch.ones((graph.num_nodes, 16), device=device)\n            \n            # Compute explosion metric: ratio of number of edges to number of nodes.\n            num_edges = graph.edge_index.size(1) if hasattr(graph, 'edge_index') else 0\n            explosion = num_edges / graph.num_nodes if graph.num_nodes > 0 else 0.0\n            graph.explosion = torch.tensor([explosion], dtype=torch.float, device=device)\n    \n    def __len__(self):\n        return len(self.graphs)\n    \n    def __getitem__(self, idx):\n        return self.graphs[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T22:26:17.340559Z","iopub.execute_input":"2025-04-07T22:26:17.340755Z","iopub.status.idle":"2025-04-07T22:26:17.357646Z","shell.execute_reply.started":"2025-04-07T22:26:17.340738Z","shell.execute_reply":"2025-04-07T22:26:17.356885Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"class AdvancedGATEncoder(nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, heads=4):\n        \"\"\"\n        Advanced encoder using GATConv layers with dense connections.\n        Args:\n            in_channels: Input node feature dimension.\n            hidden_channels: Hidden layer dimension.\n            out_channels: Output embedding dimension.\n            heads: Number of attention heads.\n        \"\"\"\n        super(AdvancedGATEncoder, self).__init__()\n        self.gat1 = GATConv(in_channels, hidden_channels, heads=heads, concat=True)\n        self.gat2 = GATConv(hidden_channels * heads, hidden_channels, heads=heads, concat=True)\n        self.gat3 = GATConv(hidden_channels * heads, out_channels, heads=1, concat=False)\n        # Dense connection projection from input to out_channels\n        self.skip_proj = nn.Linear(in_channels, out_channels)\n    \n    def forward(self, x, edge_index, batch):\n        # First GAT layer\n        out1 = F.elu(self.gat1(x, edge_index))\n        # Second GAT layer with dense connection (concatenating previous layer's output)\n        out2 = F.elu(self.gat2(out1, edge_index))\n        # Third GAT layer\n        out3 = self.gat3(out2, edge_index)\n        # Add skip connection from input (projected) to preserve low-level features\n        skip = self.skip_proj(x)\n        # Global pooling for each level\n        pooled_out3 = global_mean_pool(out3 + skip, batch)\n        # Optionally, one could also combine pooled representations from multiple layers.\n        return pooled_out3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T22:26:17.359059Z","iopub.execute_input":"2025-04-07T22:26:17.359313Z","iopub.status.idle":"2025-04-07T22:26:17.376735Z","shell.execute_reply.started":"2025-04-07T22:26:17.359293Z","shell.execute_reply":"2025-04-07T22:26:17.375928Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"class ProjectionHead(nn.Module):\n    def __init__(self, in_dim, proj_dim):\n        \"\"\"\n        Two-layer MLP for latent projection.\n        \"\"\"\n        super(ProjectionHead, self).__init__()\n        self.fc1 = nn.Linear(in_dim, proj_dim)\n        self.fc2 = nn.Linear(proj_dim, proj_dim)\n    \n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T22:26:17.377684Z","iopub.execute_input":"2025-04-07T22:26:17.377961Z","iopub.status.idle":"2025-04-07T22:26:17.395105Z","shell.execute_reply.started":"2025-04-07T22:26:17.377933Z","shell.execute_reply":"2025-04-07T22:26:17.394426Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"class ClassifierHead(nn.Module):\n    def __init__(self, in_dim, num_classes):\n        \"\"\"\n        Simple MLP classifier.\n        \"\"\"\n        super(ClassifierHead, self).__init__()\n        self.fc1 = nn.Linear(in_dim, in_dim // 2)\n        self.fc2 = nn.Linear(in_dim // 2, num_classes)\n    \n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        logits = self.fc2(x)\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T22:26:17.395822Z","iopub.execute_input":"2025-04-07T22:26:17.396028Z","iopub.status.idle":"2025-04-07T22:26:17.407239Z","shell.execute_reply.started":"2025-04-07T22:26:17.396010Z","shell.execute_reply":"2025-04-07T22:26:17.406419Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"class AdvancedGraphModel(nn.Module):\n    def __init__(self, in_channels, hidden_channels, encoder_out, proj_dim, num_classes):\n        \"\"\"\n        Combines the advanced GAT encoder, projection head, and classifier head.\n        \"\"\"\n        super(AdvancedGraphModel, self).__init__()\n        self.encoder = AdvancedGATEncoder(in_channels, hidden_channels, encoder_out)\n        self.projection_head = ProjectionHead(encoder_out, proj_dim)\n        # For classification, concatenate global physics features (pt and m0)\n        self.classifier = ClassifierHead(encoder_out + 2, num_classes)\n    \n    def forward(self, data, mode='contrastive'):\n        x = data.x\n        edge_index = data.edge_index\n        batch = data.batch\n        embedding = self.encoder(x, edge_index, batch)\n        \n        if mode == 'contrastive':\n            proj = self.projection_head(embedding)\n            return proj\n        elif mode == 'classification':\n            if hasattr(data, 'pt') and hasattr(data, 'm0'):\n                physics_features = torch.cat([data.pt.view(-1, 1), data.m0.view(-1, 1)], dim=1)\n                embedding = torch.cat([embedding, physics_features], dim=1)\n            logits = self.classifier(embedding)\n            return logits\n        else:\n            raise ValueError(\"Mode must be 'contrastive' or 'classification'.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T22:26:17.408116Z","iopub.execute_input":"2025-04-07T22:26:17.408437Z","iopub.status.idle":"2025-04-07T22:26:17.422856Z","shell.execute_reply.started":"2025-04-07T22:26:17.408408Z","shell.execute_reply":"2025-04-07T22:26:17.422211Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"def improved_nt_xent_loss(z1, z2, temperature=0.5, margin=0.5, lambda_reg=0.1):\n    batch_size = z1.shape[0]\n    z = torch.cat([z1, z2], dim=0)\n    z = F.normalize(z, dim=1)\n    \n    similarity_matrix = torch.matmul(z, z.T)\n    mask = torch.eye(2 * batch_size, dtype=torch.bool, device=z.device)\n    similarity_matrix = similarity_matrix.masked_fill(mask, -9e15)\n    similarity_matrix = similarity_matrix / temperature\n    \n    labels = torch.arange(batch_size, device=z.device)\n    labels = torch.cat([labels, labels], dim=0)\n    \n    nt_xent = F.cross_entropy(similarity_matrix, labels)\n    \n    negatives = similarity_matrix.clone()\n    negatives[mask] = -9e15\n    max_negatives, _ = negatives.max(dim=1)\n    margin_loss = F.relu(max_negatives - margin).mean()\n    \n    total_loss = nt_xent + lambda_reg * margin_loss\n    return total_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T22:26:17.425033Z","iopub.execute_input":"2025-04-07T22:26:17.425275Z","iopub.status.idle":"2025-04-07T22:26:17.437154Z","shell.execute_reply.started":"2025-04-07T22:26:17.425255Z","shell.execute_reply":"2025-04-07T22:26:17.436355Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"class AdvancedTrainer:\n    def __init__(self, model, train_loader, test_loader, device, lr=1e-3):\n        self.model = model.to(device)\n        self.train_loader = train_loader\n        self.test_loader = test_loader\n        self.device = device\n        self.optimizer = Adam(self.model.parameters(), lr=lr)\n        self.scheduler = StepLR(self.optimizer, step_size=5, gamma=0.5)\n        self.criterion_cls = nn.CrossEntropyLoss()\n    \n    def pretrain(self, epochs, drop_prob=0.2, temperature=0.5, margin=0.5, lambda_reg=0.1):\n        self.model.train()\n        for epoch in range(epochs):\n            total_loss = 0.0\n            for data in self.train_loader:\n                data = data.to(self.device)\n                if not hasattr(data, 'x') or data.x is None:\n                    data.x = torch.ones((data.num_nodes, 16), device=self.device)\n                \n                data1 = self._graph_augmentation(data, drop_prob)\n                data2 = self._graph_augmentation(data, drop_prob)\n                data1 = data1.to(self.device)\n                data2 = data2.to(self.device)\n                \n                self.optimizer.zero_grad()\n                z1 = self.model(data1, mode='contrastive')\n                z2 = self.model(data2, mode='contrastive')\n                loss = improved_nt_xent_loss(z1, z2, temperature, margin, lambda_reg)\n                loss.backward()\n                self.optimizer.step()\n                total_loss += loss.item()\n            self.scheduler.step()\n            avg_loss = total_loss / len(self.train_loader)\n            print(f\"[Pretrain] Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, LR: {self.optimizer.param_groups[0]['lr']:.6f}\")\n    \n    def finetune(self, epochs, freeze_encoder=True):\n        if freeze_encoder:\n            for param in self.model.encoder.parameters():\n                param.requires_grad = False\n        \n        optimizer_cls = Adam(self.model.classifier.parameters(), lr=1e-3)\n        scheduler_cls = StepLR(optimizer_cls, step_size=5, gamma=0.5)\n        \n        self.model.train()\n        for epoch in range(epochs):\n            total_loss = 0.0\n            for data in self.train_loader:\n                data = data.to(self.device)\n                if not hasattr(data, 'x') or data.x is None:\n                    data.x = torch.ones((data.num_nodes, 16), device=self.device)\n                optimizer_cls.zero_grad()\n                logits = self.model(data, mode='classification')\n                loss = self.criterion_cls(logits, data.y)\n                loss.backward()\n                optimizer_cls.step()\n                total_loss += loss.item()\n            scheduler_cls.step()\n            avg_loss = total_loss / len(self.train_loader)\n            metrics = self.evaluate()\n            print(f\"[Finetune] Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, Accuracy: {metrics['accuracy']*100:.2f}%, \"\n                  f\"F1: {metrics['f1']:.4f}, ROC-AUC: {metrics['roc_auc']:.4f}, LR: {optimizer_cls.param_groups[0]['lr']:.6f}\")\n    \n    def evaluate(self):\n        self.model.eval()\n        all_preds = []\n        all_labels = []\n        all_probs = []\n        with torch.no_grad():\n            for data in self.test_loader:\n                data = data.to(self.device)\n                if not hasattr(data, 'x') or data.x is None:\n                    data.x = torch.ones((data.num_nodes, 16), device=self.device)\n                logits = self.model(data, mode='classification')\n                probs = F.softmax(logits, dim=1)[:, 1]\n                preds = logits.argmax(dim=1).cpu().numpy()\n                all_preds.extend(preds)\n                all_probs.extend(probs.cpu().numpy())\n                all_labels.extend(data.y.cpu().numpy())\n        acc = accuracy_score(all_labels, all_preds)\n        f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n        try:\n            roc_auc = roc_auc_score(all_labels, all_probs)\n        except Exception:\n            roc_auc = 0.0\n        self.model.train()\n        return {\"accuracy\": acc, \"f1\": f1, \"roc_auc\": roc_auc}\n    \n    def _graph_augmentation(self, data, drop_prob):\n        node_mask = torch.rand(data.num_nodes, device=data.x.device) > drop_prob\n        if node_mask.sum() == 0:\n            node_mask[torch.randint(0, data.num_nodes, (1,))] = True\n        new_idx = torch.zeros(data.num_nodes, dtype=torch.long, device=data.x.device)\n        new_idx[node_mask] = torch.arange(node_mask.sum(), device=data.x.device)\n        \n        x = data.x[node_mask]\n        edge_index = data.edge_index\n        mask = node_mask[edge_index[0]] & node_mask[edge_index[1]]\n        edge_index = edge_index[:, mask]\n        edge_index = new_idx[edge_index]\n        \n        new_data = Data(x=x, edge_index=edge_index)\n        if hasattr(data, 'batch'):\n            new_data.batch = data.batch[node_mask]\n        if hasattr(data, 'pt'):\n            new_data.pt = data.pt\n        if hasattr(data, 'm0'):\n            new_data.m0 = data.m0\n        return new_data\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T22:26:17.438188Z","iopub.execute_input":"2025-04-07T22:26:17.438394Z","iopub.status.idle":"2025-04-07T22:26:17.455973Z","shell.execute_reply.started":"2025-04-07T22:26:17.438376Z","shell.execute_reply":"2025-04-07T22:26:17.455176Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"ggraph_path = '/kaggle/input/part-4-task-2-output/processed_jet_graphs/processed_chunk_90000_100000.pt'\nnpz_path = '/kaggle/input/genie-extracted-dataset/chunk_90000_100000.npz'\n\n# Create dataset\ndataset = JetGraphDataset(graph_path, npz_path)\n\n# Split dataset indices using stratification on labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T22:26:17.456707Z","iopub.execute_input":"2025-04-07T22:26:17.456996Z","iopub.status.idle":"2025-04-07T22:26:37.238512Z","shell.execute_reply.started":"2025-04-07T22:26:17.456975Z","shell.execute_reply":"2025-04-07T22:26:37.237530Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-76-b0e861dc17ba>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  self.graphs = torch.load(graph_path, map_location=device)\n","output_type":"stream"}],"execution_count":83},{"cell_type":"code","source":"indices = np.arange(len(dataset))\nlabels = np.array([dataset[i].y.item() for i in range(len(dataset))])\ntrain_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=42, stratify=labels)\n\ntrain_graphs = [dataset[i] for i in train_idx]\ntest_graphs = [dataset[i] for i in test_idx]\n\nprint(f\"Total graphs: {len(dataset)}; Training: {len(train_graphs)}; Testing: {len(test_graphs)}\")\n\nbatch_size = 32\ntrain_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_graphs, batch_size=batch_size, shuffle=False)\n\nin_channels = train_graphs[0].x.shape[1]\nhidden_channels = 64\nencoder_out = 64\nproj_dim = 32\nnum_classes = 2\n\nmodel = AdvancedGraphModel(in_channels, hidden_channels, encoder_out, proj_dim, num_classes)\ntrainer = AdvancedTrainer(model, train_loader, test_loader, device, lr=1e-3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T22:26:37.250155Z","iopub.execute_input":"2025-04-07T22:26:37.250505Z","iopub.status.idle":"2025-04-07T22:26:37.419455Z","shell.execute_reply.started":"2025-04-07T22:26:37.250481Z","shell.execute_reply":"2025-04-07T22:26:37.418515Z"}},"outputs":[{"name":"stdout","text":"Total graphs: 10000; Training: 8000; Testing: 2000\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n  warnings.warn(out)\n","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"pretrain_epochs = 10  # Adjust as necessary\nprint(\"Starting contrastive pre-training...\")\ntrainer.pretrain(epochs=pretrain_epochs, drop_prob=0.1, temperature=0.7, margin=0.3, lambda_reg=0.4\n                )\n\n# %% [markdown]\n# ### 6.2 Classification Fine-tuning\n# \n# Fine-tune the classifier for anomaly detection/classification. Metrics are computed after each epoch.\n\n# %%\nfinetune_epochs = 10  # Adjust as necessary\nprint(\"\\nStarting classification fine-tuning...\")\ntrainer.finetune(epochs=finetune_epochs, freeze_encoder=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T22:26:37.420141Z","iopub.execute_input":"2025-04-07T22:26:37.420413Z","iopub.status.idle":"2025-04-07T22:30:16.627028Z","shell.execute_reply.started":"2025-04-07T22:26:37.420392Z","shell.execute_reply":"2025-04-07T22:30:16.626001Z"}},"outputs":[{"name":"stdout","text":"Starting contrastive pre-training...\n[Pretrain] Epoch 1/10, Loss: 6428570146570240.0000, LR: 0.001000\n[Pretrain] Epoch 2/10, Loss: 6428570146570240.0000, LR: 0.001000\n[Pretrain] Epoch 3/10, Loss: 6428570146570240.0000, LR: 0.001000\n[Pretrain] Epoch 4/10, Loss: 6428570146570240.0000, LR: 0.001000\n[Pretrain] Epoch 5/10, Loss: 6428570146570240.0000, LR: 0.000500\n[Pretrain] Epoch 6/10, Loss: 6428570146570240.0000, LR: 0.000500\n[Pretrain] Epoch 7/10, Loss: 6428570146570240.0000, LR: 0.000500\n[Pretrain] Epoch 8/10, Loss: 6428570146570240.0000, LR: 0.000500\n[Pretrain] Epoch 9/10, Loss: 6428570146570240.0000, LR: 0.000500\n[Pretrain] Epoch 10/10, Loss: 6428570146570240.0000, LR: 0.000250\n\nStarting classification fine-tuning...\n[Finetune] Epoch 1/10, Loss: 0.6848, Accuracy: 61.85%, F1: 0.5846, ROC-AUC: 0.7160, LR: 0.001000\n[Finetune] Epoch 2/10, Loss: 0.6284, Accuracy: 65.80%, F1: 0.6573, ROC-AUC: 0.7050, LR: 0.001000\n[Finetune] Epoch 3/10, Loss: 0.6238, Accuracy: 66.75%, F1: 0.6662, ROC-AUC: 0.7129, LR: 0.001000\n[Finetune] Epoch 4/10, Loss: 0.6237, Accuracy: 60.85%, F1: 0.5849, ROC-AUC: 0.7007, LR: 0.001000\n[Finetune] Epoch 5/10, Loss: 0.6257, Accuracy: 63.45%, F1: 0.6283, ROC-AUC: 0.7054, LR: 0.000500\n[Finetune] Epoch 6/10, Loss: 0.6172, Accuracy: 63.50%, F1: 0.6295, ROC-AUC: 0.7078, LR: 0.000500\n[Finetune] Epoch 7/10, Loss: 0.6178, Accuracy: 63.80%, F1: 0.6322, ROC-AUC: 0.7092, LR: 0.000500\n[Finetune] Epoch 8/10, Loss: 0.6176, Accuracy: 66.60%, F1: 0.6660, ROC-AUC: 0.7122, LR: 0.000500\n[Finetune] Epoch 9/10, Loss: 0.6168, Accuracy: 66.95%, F1: 0.6678, ROC-AUC: 0.7149, LR: 0.000500\n[Finetune] Epoch 10/10, Loss: 0.6174, Accuracy: 63.95%, F1: 0.6343, ROC-AUC: 0.7076, LR: 0.000250\n","output_type":"stream"}],"execution_count":85},{"cell_type":"code","source":"final_metrics = trainer.evaluate()\nprint(\"Final Evaluation Metrics:\")\nprint(f\"Accuracy: {final_metrics['accuracy']*100:.2f}%\")\nprint(f\"F1 Score: {final_metrics['f1']:.4f}\")\nprint(f\"ROC-AUC: {final_metrics['roc_auc']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T22:30:16.627936Z","iopub.execute_input":"2025-04-07T22:30:16.628190Z","iopub.status.idle":"2025-04-07T22:30:17.819078Z","shell.execute_reply.started":"2025-04-07T22:30:16.628145Z","shell.execute_reply":"2025-04-07T22:30:17.818261Z"}},"outputs":[{"name":"stdout","text":"Final Evaluation Metrics:\nAccuracy: 63.95%\nF1 Score: 0.6343\nROC-AUC: 0.7076\n","output_type":"stream"}],"execution_count":86},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}